{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0165e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b36db166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (7475, 11) Val: (1840, 11) Test: (1830, 11)\n",
      "Train dates: 2013-07-01 00:00:00 → 2017-07-31 00:00:00\n",
      "Val dates: 2017-08-01 00:00:00 → 2018-07-31 00:00:00\n",
      "Test dates: 2018-08-01 00:00:00 → 2019-07-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_split_merged_expanded_data.csv\", parse_dates=[\"date\"])\n",
    "val   = pd.read_csv(\"val_split_merged_expanded_data.csv\", parse_dates=[\"date\"])\n",
    "test  = pd.read_csv(\"test_split_merged_expanded_data_filtered.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "print(\"Train:\", train.shape, \"Val:\", val.shape, \"Test:\", test.shape)\n",
    "print(\"Train dates:\", train[\"date\"].min(), \"→\", train[\"date\"].max())\n",
    "print(\"Val dates:\", val[\"date\"].min(), \"→\", val[\"date\"].max())\n",
    "print(\"Test dates:\", test[\"date\"].min(), \"→\", test[\"date\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cf06bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering done.\n"
     ]
    }
   ],
   "source": [
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    # -------------------------\n",
    "    # Calendar features\n",
    "    # -------------------------\n",
    "    df[\"Wochentag\"] = df[\"date\"].dt.day_name()\n",
    "    df[\"Month\"]     = df[\"date\"].dt.month\n",
    "    df[\"dayofyear\"] = df[\"date\"].dt.dayofyear\n",
    "\n",
    "    # Seasonality encoding (cyclical)\n",
    "    df[\"sin_season\"] = np.sin(2 * np.pi * df[\"dayofyear\"] / 365)\n",
    "    df[\"cos_season\"] = np.cos(2 * np.pi * df[\"dayofyear\"] / 365)\n",
    "\n",
    "    df[\"is_weekend\"] = df[\"Wochentag\"].isin([\"Saturday\", \"Sunday\"]).astype(int)\n",
    "\n",
    "    # Integer/calendar flags (force 0/1 and no NaNs)\n",
    "    for col in [\"KielerWoche\", \"school_holiday\", \"public_holiday\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "train_fe = add_features(train)\n",
    "val_fe   = add_features(val)\n",
    "test_fe  = add_features(test)\n",
    "\n",
    "print(\"Feature engineering done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e73ef423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lag + rolling + one-hot done.\n"
     ]
    }
   ],
   "source": [
    "train_fe[\"dataset\"] = \"train\"\n",
    "val_fe[\"dataset\"]   = \"val\"\n",
    "test_fe[\"dataset\"]  = \"test\"\n",
    "\n",
    "df_all = pd.concat([train_fe, val_fe, test_fe], ignore_index=True)\n",
    "df_all = df_all.sort_values([\"warengruppe\", \"date\"])\n",
    "\n",
    "# Lags of target (umsatz) capture short-term and weekly memory\n",
    "for lag in [1, 2, 7, 14]:\n",
    "    df_all[f\"lag_{lag}\"] = df_all.groupby(\"warengruppe\")[\"umsatz\"].shift(lag)\n",
    "\n",
    "# Rolling mean & std (shift(1) avoids leakage)\n",
    "for window in [7, 14, 30]:\n",
    "    df_all[f\"roll{window}_mean\"] = (\n",
    "        df_all.groupby(\"warengruppe\")[\"umsatz\"].shift(1).rolling(window).mean()\n",
    "    )\n",
    "    df_all[f\"roll{window}_std\"] = (\n",
    "        df_all.groupby(\"warengruppe\")[\"umsatz\"].shift(1).rolling(window).std()\n",
    "    )\n",
    "\n",
    "# One-hot weekday (done on ALL so columns match across splits)\n",
    "df_all = pd.get_dummies(df_all, columns=[\"Wochentag\"], drop_first=True)\n",
    "\n",
    "train_fe = df_all[df_all[\"dataset\"] == \"train\"].copy()\n",
    "val_fe   = df_all[df_all[\"dataset\"] == \"val\"].copy()\n",
    "test_fe  = df_all[df_all[\"dataset\"] == \"test\"].copy()\n",
    "\n",
    "print(\"Lag + rolling + one-hot done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5568012d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 24\n"
     ]
    }
   ],
   "source": [
    "weekday_cols = [c for c in train_fe.columns if c.startswith(\"Wochentag_\")]\n",
    "\n",
    "feature_cols = [\n",
    "    \"Temperatur\",\n",
    "    \"KielerWoche\",\n",
    "    \"school_holiday\",\n",
    "    \"public_holiday\",\n",
    "    \"Month\",\n",
    "    \"sin_season\",\n",
    "    \"cos_season\",\n",
    "    \"is_weekend\",\n",
    "    \"lag_1\",\n",
    "    \"lag_2\",\n",
    "    \"lag_7\",\n",
    "    \"lag_14\",\n",
    "    \"roll7_mean\",\n",
    "    \"roll7_std\",\n",
    "    \"roll14_mean\",\n",
    "    \"roll14_std\",\n",
    "    \"roll30_mean\",\n",
    "    \"roll30_std\",\n",
    "] + weekday_cols\n",
    "\n",
    "target_col = \"umsatz\"\n",
    "\n",
    "print(\"Number of features:\", len(feature_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4515606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim: int) -> tf.keras.Model:\n",
    "    model = Sequential([\n",
    "        Dense(64, activation=\"relu\", input_shape=(input_dim,)),\n",
    "        Dropout(0.1),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"mse\"\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e511272d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Warengruppe 1\n",
      "==============================\n",
      "Rows: train=1432, val=357, test=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2026-01-06 13:33:04.456461: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.629 | MSE: 590.07 | MAE: 17.95\n",
      "NN R² (val):   0.526 | MSE: 849.74 | MAE: 21.77\n",
      "\n",
      "==============================\n",
      " Warengruppe 2\n",
      "==============================\n",
      "Rows: train=1432, val=357, test=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.880 | MSE: 2274.56 | MAE: 32.44\n",
      "NN R² (val):   0.890 | MSE: 1770.26 | MAE: 32.32\n",
      "\n",
      "==============================\n",
      " Warengruppe 3\n",
      "==============================\n",
      "Rows: train=1432, val=357, test=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.864 | MSE: 734.83 | MAE: 18.87\n",
      "NN R² (val):   0.868 | MSE: 757.80 | MAE: 20.65\n",
      "\n",
      "==============================\n",
      " Warengruppe 4\n",
      "==============================\n",
      "Rows: train=1379, val=357, test=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.596 | MSE: 568.07 | MAE: 16.80\n",
      "NN R² (val):   0.018 | MSE: 687.28 | MAE: 20.16\n",
      "\n",
      "==============================\n",
      " Warengruppe 5\n",
      "==============================\n",
      "Rows: train=1432, val=357, test=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.321 | MSE: 7059.57 | MAE: 37.55\n",
      "NN R² (val):   0.205 | MSE: 6171.55 | MAE: 44.50\n",
      "\n",
      "==============================\n",
      " Warengruppe 6\n",
      "==============================\n",
      "Rows: train=188, val=55, test=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.501 | MSE: 544.53 | MAE: 17.81\n",
      "NN R² (val):   0.485 | MSE: 501.87 | MAE: 17.58\n",
      "\n",
      "==============================\n",
      " Combined (weighted) metrics \n",
      "==============================\n",
      "Weighted R² (train): 0.653\n",
      "Weighted R² (val):   0.501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warengruppe</th>\n",
       "      <th>n_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "      <th>mse_train</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>mse_val</th>\n",
       "      <th>mae_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>357</td>\n",
       "      <td>0.628801</td>\n",
       "      <td>0.526486</td>\n",
       "      <td>590.073058</td>\n",
       "      <td>17.950625</td>\n",
       "      <td>849.735055</td>\n",
       "      <td>21.771578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>357</td>\n",
       "      <td>0.879963</td>\n",
       "      <td>0.889854</td>\n",
       "      <td>2274.560588</td>\n",
       "      <td>32.436344</td>\n",
       "      <td>1770.257729</td>\n",
       "      <td>32.316728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>357</td>\n",
       "      <td>0.864297</td>\n",
       "      <td>0.867996</td>\n",
       "      <td>734.830010</td>\n",
       "      <td>18.870243</td>\n",
       "      <td>757.795823</td>\n",
       "      <td>20.651716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>357</td>\n",
       "      <td>0.595968</td>\n",
       "      <td>0.017907</td>\n",
       "      <td>568.071318</td>\n",
       "      <td>16.798568</td>\n",
       "      <td>687.276524</td>\n",
       "      <td>20.161902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>357</td>\n",
       "      <td>0.321235</td>\n",
       "      <td>0.204896</td>\n",
       "      <td>7059.565460</td>\n",
       "      <td>37.549809</td>\n",
       "      <td>6171.549949</td>\n",
       "      <td>44.504402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>0.501357</td>\n",
       "      <td>0.485100</td>\n",
       "      <td>544.529983</td>\n",
       "      <td>17.812382</td>\n",
       "      <td>501.874114</td>\n",
       "      <td>17.576968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   warengruppe  n_val  r2_train    r2_val    mse_train  mae_train  \\\n",
       "0            1    357  0.628801  0.526486   590.073058  17.950625   \n",
       "1            2    357  0.879963  0.889854  2274.560588  32.436344   \n",
       "2            3    357  0.864297  0.867996   734.830010  18.870243   \n",
       "3            4    357  0.595968  0.017907   568.071318  16.798568   \n",
       "4            5    357  0.321235  0.204896  7059.565460  37.549809   \n",
       "5            6     55  0.501357  0.485100   544.529983  17.812382   \n",
       "\n",
       "       mse_val    mae_val  \n",
       "0   849.735055  21.771578  \n",
       "1  1770.257729  32.316728  \n",
       "2   757.795823  20.651716  \n",
       "3   687.276524  20.161902  \n",
       "4  6171.549949  44.504402  \n",
       "5   501.874114  17.576968  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: submission_neural_net.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>umsatz_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1808011</td>\n",
       "      <td>140.604126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1808012</td>\n",
       "      <td>624.095398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1808013</td>\n",
       "      <td>318.323212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1808014</td>\n",
       "      <td>78.437088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>1808015</td>\n",
       "      <td>284.120148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  umsatz_Prediction\n",
       "0     1808011         140.604126\n",
       "355   1808012         624.095398\n",
       "710   1808013         318.323212\n",
       "1065  1808014          78.437088\n",
       "1419  1808015         284.120148"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_groups = sorted(train_fe[\"warengruppe\"].dropna().unique())\n",
    "\n",
    "pred_list = []\n",
    "models_by_wg = {}\n",
    "results = []\n",
    "\n",
    "for wg in product_groups:\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\" Warengruppe {wg}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    train_wg = train_fe[train_fe[\"warengruppe\"] == wg].copy()\n",
    "    val_wg   = val_fe[val_fe[\"warengruppe\"] == wg].copy()\n",
    "    test_wg  = test_fe[test_fe[\"warengruppe\"] == wg].copy()\n",
    "\n",
    "    # Drop rows without target in train/val\n",
    "    train_wg = train_wg.dropna(subset=[target_col])\n",
    "    val_wg   = val_wg.dropna(subset=[target_col])\n",
    "\n",
    "    # Drop rows with missing FEATURES in train/val only\n",
    "    train_wg = train_wg.dropna(subset=feature_cols)\n",
    "    val_wg   = val_wg.dropna(subset=feature_cols)\n",
    "\n",
    "    # DO NOT drop test rows\n",
    "\n",
    "    print(f\"Rows: train={len(train_wg)}, val={len(val_wg)}, test={len(test_wg)}\")\n",
    "\n",
    "    if len(train_wg) < 50 or len(val_wg) < 20:\n",
    "        print(\"⚠️ Too few rows for stable NN training → skipping this WG.\")\n",
    "        continue\n",
    "\n",
    "    if len(test_wg) == 0:\n",
    "        print(\"⚠️ No test rows for this WG → skipping prediction.\")\n",
    "        continue\n",
    "\n",
    "    # ✅ Build X/y AFTER filtering\n",
    "    X_train = train_wg[feature_cols].to_numpy()\n",
    "    y_train = train_wg[target_col].to_numpy()\n",
    "\n",
    "    X_val   = val_wg[feature_cols].to_numpy()\n",
    "    y_val   = val_wg[target_col].to_numpy()\n",
    "\n",
    "    X_test  = test_wg[feature_cols].to_numpy()\n",
    "\n",
    "    # ✅ Impute\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_val   = imputer.transform(X_val)\n",
    "    X_test  = imputer.transform(X_test)\n",
    "\n",
    "    # ✅ Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val   = scaler.transform(X_val)\n",
    "    X_test  = scaler.transform(X_test)\n",
    "\n",
    "    # Train\n",
    "    model = build_model(input_dim=X_train.shape[1])\n",
    "\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        callbacks=[es],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    y_train_pred = model.predict(X_train, verbose=0).ravel()\n",
    "    y_val_pred   = model.predict(X_val, verbose=0).ravel()\n",
    "\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_val   = r2_score(y_val, y_val_pred)\n",
    "\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "    mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "    mae_val = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    print(f\"NN R² (train): {r2_train:.3f} | MSE: {mse_train:.2f} | MAE: {mae_train:.2f}\")\n",
    "    print(f\"NN R² (val):   {r2_val:.3f} | MSE: {mse_val:.2f} | MAE: {mae_val:.2f}\")\n",
    "\n",
    "    results.append({\n",
    "    \"warengruppe\": wg,\n",
    "    \"n_val\": len(val_wg),\n",
    "    \"r2_train\": r2_train,\n",
    "    \"r2_val\": r2_val,\n",
    "    \"mse_train\": mse_train,\n",
    "    \"mae_train\": mae_train,\n",
    "    \"mse_val\": mse_val,\n",
    "    \"mae_val\": mae_val\n",
    "})\n",
    "\n",
    "\n",
    "    # Predict test\n",
    "    y_test_pred = model.predict(X_test, verbose=0).ravel()\n",
    "\n",
    "    pred_list.append(pd.DataFrame({\n",
    "        \"id\": test_wg[\"id\"].values,\n",
    "        \"umsatz_Prediction\": y_test_pred\n",
    "    }))\n",
    "\n",
    "    models_by_wg[wg] = (model, scaler, imputer)\n",
    "\n",
    "# ==============================\n",
    "# Combined (weighted) evaluation\n",
    "# ==============================\n",
    "results_df = pd.DataFrame(results).sort_values(\"warengruppe\")\n",
    "\n",
    "weighted_r2_train = (\n",
    "    (results_df[\"r2_train\"] * results_df[\"n_val\"]).sum()\n",
    "    / results_df[\"n_val\"].sum()\n",
    ")\n",
    "\n",
    "weighted_r2_val = (\n",
    "    (results_df[\"r2_val\"] * results_df[\"n_val\"]).sum()\n",
    "    / results_df[\"n_val\"].sum()\n",
    ")\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\" Combined (weighted) metrics \")\n",
    "print(\"==============================\")\n",
    "print(f\"Weighted R² (train): {weighted_r2_train:.3f}\")\n",
    "print(f\"Weighted R² (val):   {weighted_r2_val:.3f}\")\n",
    "\n",
    "display(results_df)  # optional (notebook only)\n",
    "\n",
    "\n",
    "# Submission\n",
    "if len(pred_list) == 0:\n",
    "    raise ValueError(\"No predictions generated. Check test split and IDs.\")\n",
    "\n",
    "submission = pd.concat(pred_list, ignore_index=True)\n",
    "submission = submission.dropna(subset=[\"id\"]).copy()\n",
    "submission[\"id\"] = submission[\"id\"].astype(int)\n",
    "submission = submission.sort_values(\"id\")\n",
    "submission.to_csv(\"submission_neural_net.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved: submission_neural_net.csv\")\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
