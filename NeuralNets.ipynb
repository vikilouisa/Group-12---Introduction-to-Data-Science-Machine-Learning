{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0165e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e35f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Mean Absolute Percentage Error (MAPE)\n",
    "    Ignores zero targets to avoid division by zero.\n",
    "    Returns percentage.\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    non_zero_mask = y_true != 0\n",
    "    if non_zero_mask.sum() == 0:\n",
    "        return np.nan\n",
    "\n",
    "    return np.mean(\n",
    "        np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])\n",
    "    ) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b36db166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (7475, 11) Val: (1840, 11) Test: (1830, 11)\n",
      "Train dates: 2013-07-01 00:00:00 → 2017-07-31 00:00:00\n",
      "Val dates: 2017-08-01 00:00:00 → 2018-07-31 00:00:00\n",
      "Test dates: 2018-08-01 00:00:00 → 2019-07-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_split_merged_expanded_data.csv\", parse_dates=[\"date\"])\n",
    "val   = pd.read_csv(\"val_split_merged_expanded_data.csv\", parse_dates=[\"date\"])\n",
    "test  = pd.read_csv(\"test_split_merged_expanded_data_filtered.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "print(\"Train:\", train.shape, \"Val:\", val.shape, \"Test:\", test.shape)\n",
    "print(\"Train dates:\", train[\"date\"].min(), \"→\", train[\"date\"].max())\n",
    "print(\"Val dates:\", val[\"date\"].min(), \"→\", val[\"date\"].max())\n",
    "print(\"Test dates:\", test[\"date\"].min(), \"→\", test[\"date\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cf06bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering done.\n"
     ]
    }
   ],
   "source": [
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    # -------------------------\n",
    "    # Calendar features\n",
    "    # -------------------------\n",
    "    df[\"Wochentag\"] = df[\"date\"].dt.day_name()\n",
    "    df[\"Month\"]     = df[\"date\"].dt.month\n",
    "    df[\"dayofyear\"] = df[\"date\"].dt.dayofyear\n",
    "\n",
    "    # Seasonality encoding (cyclical)\n",
    "    df[\"sin_season\"] = np.sin(2 * np.pi * df[\"dayofyear\"] / 365)\n",
    "    df[\"cos_season\"] = np.cos(2 * np.pi * df[\"dayofyear\"] / 365)\n",
    "\n",
    "    df[\"is_weekend\"] = df[\"Wochentag\"].isin([\"Saturday\", \"Sunday\"]).astype(int)\n",
    "\n",
    "    # Integer/calendar flags (force 0/1 and no NaNs)\n",
    "    for col in [\"KielerWoche\", \"school_holiday\", \"public_holiday\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "train_fe = add_features(train)\n",
    "val_fe   = add_features(val)\n",
    "test_fe  = add_features(test)\n",
    "\n",
    "print(\"Feature engineering done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e73ef423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lag + rolling + one-hot done.\n"
     ]
    }
   ],
   "source": [
    "train_fe[\"dataset\"] = \"train\"\n",
    "val_fe[\"dataset\"]   = \"val\"\n",
    "test_fe[\"dataset\"]  = \"test\"\n",
    "\n",
    "df_all = pd.concat([train_fe, val_fe, test_fe], ignore_index=True)\n",
    "df_all = df_all.sort_values([\"warengruppe\", \"date\"])\n",
    "\n",
    "# Lags of target (umsatz) capture short-term and weekly memory\n",
    "for lag in [1, 2, 7, 14]:\n",
    "    df_all[f\"lag_{lag}\"] = df_all.groupby(\"warengruppe\")[\"umsatz\"].shift(lag)\n",
    "\n",
    "# Rolling mean & std (shift(1) avoids leakage)\n",
    "for window in [7, 14, 30]:\n",
    "    df_all[f\"roll{window}_mean\"] = (\n",
    "        df_all.groupby(\"warengruppe\")[\"umsatz\"].shift(1).rolling(window).mean()\n",
    "    )\n",
    "    df_all[f\"roll{window}_std\"] = (\n",
    "        df_all.groupby(\"warengruppe\")[\"umsatz\"].shift(1).rolling(window).std()\n",
    "    )\n",
    "\n",
    "# One-hot weekday (done on ALL so columns match across splits)\n",
    "df_all = pd.get_dummies(df_all, columns=[\"Wochentag\"], drop_first=False)\n",
    "\n",
    "train_fe = df_all[df_all[\"dataset\"] == \"train\"].copy()\n",
    "val_fe   = df_all[df_all[\"dataset\"] == \"val\"].copy()\n",
    "test_fe  = df_all[df_all[\"dataset\"] == \"test\"].copy()\n",
    "\n",
    "print(\"Lag + rolling + one-hot done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5568012d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: nn_feature_dataset_train.csv\n",
      "Number of features: 25\n"
     ]
    }
   ],
   "source": [
    "weekday_cols = [c for c in train_fe.columns if c.startswith(\"Wochentag_\")]\n",
    "\n",
    "feature_cols = [\n",
    "    \"Temperatur\",\n",
    "    \"KielerWoche\",\n",
    "    \"school_holiday\",\n",
    "    \"public_holiday\",\n",
    "    \"Month\",\n",
    "    \"sin_season\",\n",
    "    \"cos_season\",\n",
    "    \"is_weekend\",\n",
    "    \"lag_1\",\n",
    "    \"lag_2\",\n",
    "    \"lag_7\",\n",
    "    \"lag_14\",\n",
    "    \"roll7_mean\",\n",
    "    \"roll7_std\",\n",
    "    \"roll14_mean\",\n",
    "    \"roll14_std\",\n",
    "    \"roll30_mean\",\n",
    "    \"roll30_std\",\n",
    "] + weekday_cols\n",
    "\n",
    "target_col = \"umsatz\"\n",
    "\n",
    "# Export feature dataset (train only)\n",
    "features_dataset = train_fe[feature_cols + [target_col]].copy()\n",
    "\n",
    "features_dataset.to_csv(\n",
    "    \"nn_feature_dataset_train.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Saved: nn_feature_dataset_train.csv\")\n",
    "\n",
    "\n",
    "print(\"Number of features:\", len(feature_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4515606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim: int) -> tf.keras.Model:\n",
    "    model = Sequential([\n",
    "        Dense(64, activation=\"relu\", input_shape=(input_dim,)),\n",
    "        Dropout(0.1),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"mse\"\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e511272d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Warengruppe 1\n",
      "==============================\n",
      "Rows: train=1432, val=357, test=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.661 | MSE: 538.79 | MAE: 17.45 | MAPE: 15.86%\n",
      "NN R² (val):   0.542 | MSE: 821.00 | MAE: 21.65 | MAPE: 18.19%\n",
      "\n",
      "==============================\n",
      " Warengruppe 2\n",
      "==============================\n",
      "Rows: train=1432, val=357, test=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.881 | MSE: 2261.19 | MAE: 32.09 | MAPE: 7.94%\n",
      "NN R² (val):   0.889 | MSE: 1786.69 | MAE: 32.20 | MAPE: 9.27%\n",
      "\n",
      "==============================\n",
      " Warengruppe 3\n",
      "==============================\n",
      "Rows: train=1432, val=357, test=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.865 | MSE: 732.30 | MAE: 18.90 | MAPE: 12.98%\n",
      "NN R² (val):   0.871 | MSE: 740.86 | MAE: 20.37 | MAPE: 14.23%\n",
      "\n",
      "==============================\n",
      " Warengruppe 4\n",
      "==============================\n",
      "Rows: train=1379, val=357, test=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.612 | MSE: 545.91 | MAE: 16.50 | MAPE: 19.51%\n",
      "NN R² (val):   0.064 | MSE: 655.01 | MAE: 19.41 | MAPE: 24.74%\n",
      "\n",
      "==============================\n",
      " Warengruppe 5\n",
      "==============================\n",
      "Rows: train=1432, val=357, test=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.360 | MSE: 6661.46 | MAE: 37.14 | MAPE: 12.81%\n",
      "NN R² (val):   0.225 | MSE: 6015.01 | MAE: 43.61 | MAPE: 16.37%\n",
      "\n",
      "==============================\n",
      " Warengruppe 6\n",
      "==============================\n",
      "Rows: train=188, val=55, test=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.397 | MSE: 658.06 | MAE: 19.43 | MAPE: 34.19%\n",
      "NN R² (val):   0.438 | MSE: 547.34 | MAE: 17.49 | MAPE: 44.68%\n",
      "\n",
      "==============================\n",
      " Combined (weighted) metrics \n",
      "==============================\n",
      "Weighted R² (train): 0.667\n",
      "Weighted R² (val):   0.516\n",
      "Weighted MAPE (val): 17.40%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warengruppe</th>\n",
       "      <th>n_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "      <th>mse_train</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>mape_train</th>\n",
       "      <th>mse_val</th>\n",
       "      <th>mae_val</th>\n",
       "      <th>mape_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>357</td>\n",
       "      <td>0.661061</td>\n",
       "      <td>0.542499</td>\n",
       "      <td>538.790404</td>\n",
       "      <td>17.452540</td>\n",
       "      <td>15.858227</td>\n",
       "      <td>821.000416</td>\n",
       "      <td>21.651719</td>\n",
       "      <td>18.187076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>357</td>\n",
       "      <td>0.880669</td>\n",
       "      <td>0.888832</td>\n",
       "      <td>2261.186567</td>\n",
       "      <td>32.088368</td>\n",
       "      <td>7.941042</td>\n",
       "      <td>1786.687257</td>\n",
       "      <td>32.201293</td>\n",
       "      <td>9.271553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>357</td>\n",
       "      <td>0.864765</td>\n",
       "      <td>0.870947</td>\n",
       "      <td>732.295699</td>\n",
       "      <td>18.896506</td>\n",
       "      <td>12.980236</td>\n",
       "      <td>740.859541</td>\n",
       "      <td>20.371112</td>\n",
       "      <td>14.232466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>357</td>\n",
       "      <td>0.611727</td>\n",
       "      <td>0.064010</td>\n",
       "      <td>545.914718</td>\n",
       "      <td>16.502429</td>\n",
       "      <td>19.511427</td>\n",
       "      <td>655.013706</td>\n",
       "      <td>19.413531</td>\n",
       "      <td>24.741644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>357</td>\n",
       "      <td>0.359512</td>\n",
       "      <td>0.225063</td>\n",
       "      <td>6661.455705</td>\n",
       "      <td>37.138612</td>\n",
       "      <td>12.812459</td>\n",
       "      <td>6015.014628</td>\n",
       "      <td>43.612958</td>\n",
       "      <td>16.367425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>0.397396</td>\n",
       "      <td>0.438451</td>\n",
       "      <td>658.057627</td>\n",
       "      <td>19.431257</td>\n",
       "      <td>34.187437</td>\n",
       "      <td>547.343324</td>\n",
       "      <td>17.490760</td>\n",
       "      <td>44.681847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   warengruppe  n_val  r2_train    r2_val    mse_train  mae_train  mape_train  \\\n",
       "0            1    357  0.661061  0.542499   538.790404  17.452540   15.858227   \n",
       "1            2    357  0.880669  0.888832  2261.186567  32.088368    7.941042   \n",
       "2            3    357  0.864765  0.870947   732.295699  18.896506   12.980236   \n",
       "3            4    357  0.611727  0.064010   545.914718  16.502429   19.511427   \n",
       "4            5    357  0.359512  0.225063  6661.455705  37.138612   12.812459   \n",
       "5            6     55  0.397396  0.438451   658.057627  19.431257   34.187437   \n",
       "\n",
       "       mse_val    mae_val   mape_val  \n",
       "0   821.000416  21.651719  18.187076  \n",
       "1  1786.687257  32.201293   9.271553  \n",
       "2   740.859541  20.371112  14.232466  \n",
       "3   655.013706  19.413531  24.741644  \n",
       "4  6015.014628  43.612958  16.367425  \n",
       "5   547.343324  17.490760  44.681847  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: submission_neural_net.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>umsatz_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1808011</td>\n",
       "      <td>137.904053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1808012</td>\n",
       "      <td>638.915405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1808013</td>\n",
       "      <td>324.686432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1808014</td>\n",
       "      <td>81.097221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>1808015</td>\n",
       "      <td>278.371094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  umsatz_Prediction\n",
       "0     1808011         137.904053\n",
       "355   1808012         638.915405\n",
       "710   1808013         324.686432\n",
       "1065  1808014          81.097221\n",
       "1419  1808015         278.371094"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_groups = sorted(train_fe[\"warengruppe\"].dropna().unique())\n",
    "\n",
    "pred_list = []\n",
    "models_by_wg = {}\n",
    "results = []\n",
    "\n",
    "for wg in product_groups:\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\" Warengruppe {wg}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    train_wg = train_fe[train_fe[\"warengruppe\"] == wg].copy()\n",
    "    val_wg   = val_fe[val_fe[\"warengruppe\"] == wg].copy()\n",
    "    test_wg  = test_fe[test_fe[\"warengruppe\"] == wg].copy()\n",
    "\n",
    "    # Drop rows without target in train/val\n",
    "    train_wg = train_wg.dropna(subset=[target_col])\n",
    "    val_wg   = val_wg.dropna(subset=[target_col])\n",
    "\n",
    "    # Drop rows with missing FEATURES in train/val only\n",
    "    train_wg = train_wg.dropna(subset=feature_cols)\n",
    "    val_wg   = val_wg.dropna(subset=feature_cols)\n",
    "\n",
    "    # DO NOT drop test rows\n",
    "    print(f\"Rows: train={len(train_wg)}, val={len(val_wg)}, test={len(test_wg)}\")\n",
    "\n",
    "    if len(train_wg) < 50 or len(val_wg) < 20:\n",
    "        print(\"⚠️ Too few rows for stable NN training → skipping this WG.\")\n",
    "        continue\n",
    "\n",
    "    if len(test_wg) == 0:\n",
    "        print(\"⚠️ No test rows for this WG → skipping prediction.\")\n",
    "        continue\n",
    "\n",
    "    # ✅ Build X/y AFTER filtering\n",
    "    X_train = train_wg[feature_cols].to_numpy()\n",
    "    y_train = train_wg[target_col].to_numpy()\n",
    "\n",
    "    X_val   = val_wg[feature_cols].to_numpy()\n",
    "    y_val   = val_wg[target_col].to_numpy()\n",
    "\n",
    "    X_test  = test_wg[feature_cols].to_numpy()\n",
    "\n",
    "    # ✅ Impute\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_val   = imputer.transform(X_val)\n",
    "    X_test  = imputer.transform(X_test)\n",
    "\n",
    "    # ✅ Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val   = scaler.transform(X_val)\n",
    "    X_test  = scaler.transform(X_test)\n",
    "\n",
    "    # Train\n",
    "    model = build_model(input_dim=X_train.shape[1])\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        callbacks=[es],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    y_train_pred = model.predict(X_train, verbose=0).ravel()\n",
    "    y_val_pred   = model.predict(X_val, verbose=0).ravel()\n",
    "\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_val   = r2_score(y_val, y_val_pred)\n",
    "\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "    mape_train = mape(y_train, y_train_pred)\n",
    "\n",
    "    mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "    mae_val = mean_absolute_error(y_val, y_val_pred)\n",
    "    mape_val = mape(y_val, y_val_pred)\n",
    "\n",
    "    print(\n",
    "        f\"NN R² (train): {r2_train:.3f} | MSE: {mse_train:.2f} | MAE: {mae_train:.2f} | MAPE: {mape_train:.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"NN R² (val):   {r2_val:.3f} | MSE: {mse_val:.2f} | MAE: {mae_val:.2f} | MAPE: {mape_val:.2f}%\"\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"warengruppe\": wg,\n",
    "        \"n_val\": len(val_wg),\n",
    "        \"r2_train\": r2_train,\n",
    "        \"r2_val\": r2_val,\n",
    "        \"mse_train\": mse_train,\n",
    "        \"mae_train\": mae_train,\n",
    "        \"mape_train\": mape_train,\n",
    "        \"mse_val\": mse_val,\n",
    "        \"mae_val\": mae_val,\n",
    "        \"mape_val\": mape_val\n",
    "    })\n",
    "\n",
    "    # Predict test\n",
    "    y_test_pred = model.predict(X_test, verbose=0).ravel()\n",
    "\n",
    "    pred_list.append(pd.DataFrame({\n",
    "        \"id\": test_wg[\"id\"].values,\n",
    "        \"umsatz_Prediction\": y_test_pred\n",
    "    }))\n",
    "\n",
    "    models_by_wg[wg] = (model, scaler, imputer)\n",
    "\n",
    "# ==============================\n",
    "# Combined (weighted) evaluation\n",
    "# ==============================\n",
    "results_df = pd.DataFrame(results).sort_values(\"warengruppe\")\n",
    "\n",
    "weighted_r2_train = (results_df[\"r2_train\"] * results_df[\"n_val\"]).sum() / results_df[\"n_val\"].sum()\n",
    "weighted_r2_val   = (results_df[\"r2_val\"]   * results_df[\"n_val\"]).sum() / results_df[\"n_val\"].sum()\n",
    "\n",
    "weighted_mape_val = (results_df[\"mape_val\"] * results_df[\"n_val\"]).sum() / results_df[\"n_val\"].sum()\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\" Combined (weighted) metrics \")\n",
    "print(\"==============================\")\n",
    "print(f\"Weighted R² (train): {weighted_r2_train:.3f}\")\n",
    "print(f\"Weighted R² (val):   {weighted_r2_val:.3f}\")\n",
    "print(f\"Weighted MAPE (val): {weighted_mape_val:.2f}%\")\n",
    "\n",
    "display(results_df)  # optional (notebook only)\n",
    "\n",
    "# Submission\n",
    "if len(pred_list) == 0:\n",
    "    raise ValueError(\"No predictions generated. Check test split and IDs.\")\n",
    "\n",
    "submission = pd.concat(pred_list, ignore_index=True)\n",
    "submission = submission.dropna(subset=[\"id\"]).copy()\n",
    "submission[\"id\"] = submission[\"id\"].astype(int)\n",
    "submission = submission.sort_values(\"id\")\n",
    "submission.to_csv(\"submission_neural_net.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved: submission_neural_net.csv\")\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
