{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0165e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e35f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Mean Absolute Percentage Error (MAPE)\n",
    "    Ignores zero targets to avoid division by zero.\n",
    "    Returns percentage.\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    non_zero_mask = y_true != 0\n",
    "    if non_zero_mask.sum() == 0:\n",
    "        return np.nan\n",
    "\n",
    "    return np.mean(\n",
    "        np.abs((y_true[non_zero_mask] - y_pred[non_zero_mask]) / y_true[non_zero_mask])\n",
    "    ) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b36db166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (7475, 11) Val: (1840, 11) Test: (1830, 11)\n",
      "Train dates: 2013-07-01 00:00:00 → 2017-07-31 00:00:00\n",
      "Val dates: 2017-08-01 00:00:00 → 2018-07-31 00:00:00\n",
      "Test dates: 2018-08-01 00:00:00 → 2019-07-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_split_merged_expanded_data.csv\", parse_dates=[\"date\"])\n",
    "val   = pd.read_csv(\"val_split_merged_expanded_data.csv\", parse_dates=[\"date\"])\n",
    "test  = pd.read_csv(\"test_split_merged_expanded_data_filtered.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "print(\"Train:\", train.shape, \"Val:\", val.shape, \"Test:\", test.shape)\n",
    "print(\"Train dates:\", train[\"date\"].min(), \"→\", train[\"date\"].max())\n",
    "print(\"Val dates:\", val[\"date\"].min(), \"→\", val[\"date\"].max())\n",
    "print(\"Test dates:\", test[\"date\"].min(), \"→\", test[\"date\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cf06bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering done.\n"
     ]
    }
   ],
   "source": [
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    # -------------------------\n",
    "    # Calendar features\n",
    "    # -------------------------\n",
    "    df[\"Wochentag\"] = df[\"date\"].dt.day_name()\n",
    "    df[\"Month\"]     = df[\"date\"].dt.month\n",
    "    df[\"dayofyear\"] = df[\"date\"].dt.dayofyear\n",
    "\n",
    "    # Seasonality encoding (cyclical)\n",
    "    df[\"sin_season\"] = np.sin(2 * np.pi * df[\"dayofyear\"] / 365)\n",
    "    df[\"cos_season\"] = np.cos(2 * np.pi * df[\"dayofyear\"] / 365)\n",
    "\n",
    "    df[\"is_weekend\"] = df[\"Wochentag\"].isin([\"Saturday\", \"Sunday\"]).astype(int)\n",
    "\n",
    "    # Integer/calendar flags (force 0/1 and no NaNs)\n",
    "    for col in [\"KielerWoche\", \"school_holiday\", \"public_holiday\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "train_fe = add_features(train)\n",
    "val_fe   = add_features(val)\n",
    "test_fe  = add_features(test)\n",
    "\n",
    "print(\"Feature engineering done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e73ef423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     roll7_mean  roll7_std\n",
      "0           NaN        NaN\n",
      "5    148.828353        NaN\n",
      "10   154.311055   7.753712\n",
      "1           NaN        NaN\n",
      "6    535.856285        NaN\n",
      "11   541.318536   7.724790\n",
      "2           NaN        NaN\n",
      "7    201.198426        NaN\n",
      "12   233.229840  45.299260\n",
      "3           NaN        NaN\n",
      "8     65.890169        NaN\n",
      "13    70.217043   6.119124\n",
      "4           NaN        NaN\n",
      "9    317.475875        NaN\n",
      "14   350.552278  46.777098\n",
      "612         NaN        NaN\n",
      "618   48.605400        NaN\n",
      "624   59.368168  15.220853\n",
      "Lag + rolling + one-hot done.\n"
     ]
    }
   ],
   "source": [
    "train_fe[\"dataset\"] = \"train\"\n",
    "val_fe[\"dataset\"]   = \"val\"\n",
    "test_fe[\"dataset\"]  = \"test\"\n",
    "\n",
    "df_all = pd.concat([train_fe, val_fe, test_fe], ignore_index=True)\n",
    "df_all = df_all.sort_values([\"warengruppe\", \"date\"])\n",
    "\n",
    "# Lags of target (umsatz) capture short-term and weekly memory\n",
    "for lag in [1, 2, 7, 14]:\n",
    "    df_all[f\"lag_{lag}\"] = df_all.groupby(\"warengruppe\")[\"umsatz\"].shift(lag)\n",
    "\n",
    "# Rolling mean & std PER warengruppe (shift(1) avoids leakage)\n",
    "for window in [7, 14, 30]:\n",
    "    df_all[f\"roll{window}_mean\"] = (\n",
    "        df_all.groupby(\"warengruppe\")[\"umsatz\"]\n",
    "              .transform(lambda s: s.shift(1).rolling(window, min_periods=1).mean())\n",
    "    )\n",
    "    df_all[f\"roll{window}_std\"] = (\n",
    "        df_all.groupby(\"warengruppe\")[\"umsatz\"]\n",
    "              .transform(lambda s: s.shift(1).rolling(window, min_periods=2).std())\n",
    "    )\n",
    "\n",
    "\n",
    "# Sanity check: first rows per WG should have NaNs in rolling features (expected)\n",
    "print(df_all.groupby(\"warengruppe\")[[\"roll7_mean\", \"roll7_std\"]].head(3))\n",
    "\n",
    "# -------------------------\n",
    "# Missingness flags for lag/rolling features\n",
    "# (keeps information about \"empty cells\" after imputation)\n",
    "# -------------------------\n",
    "lag_roll_cols = [c for c in df_all.columns if c.startswith(\"lag_\") or c.startswith(\"roll\")]\n",
    "for c in lag_roll_cols:\n",
    "    df_all[c + \"_isna\"] = df_all[c].isna().astype(int)\n",
    "\n",
    "\n",
    "# One-hot weekday (done on ALL so columns match across splits)\n",
    "df_all = pd.get_dummies(df_all, columns=[\"Wochentag\"], drop_first=False)\n",
    "\n",
    "train_fe = df_all[df_all[\"dataset\"] == \"train\"].copy()\n",
    "val_fe   = df_all[df_all[\"dataset\"] == \"val\"].copy()\n",
    "test_fe  = df_all[df_all[\"dataset\"] == \"test\"].copy()\n",
    "\n",
    "print(\"Lag + rolling + one-hot done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5568012d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA-flag features: 10\n",
      "Example NA-flag cols: ['lag_1_isna', 'lag_2_isna', 'lag_7_isna', 'lag_14_isna', 'roll7_mean_isna']\n",
      "Saved: nn_feature_dataset_train.csv\n",
      "Number of features: 35\n"
     ]
    }
   ],
   "source": [
    "weekday_cols = [c for c in train_fe.columns if c.startswith(\"Wochentag_\")]\n",
    "\n",
    "na_flag_cols = [c for c in train_fe.columns if c.endswith(\"_isna\")]\n",
    "\n",
    "\n",
    "\n",
    "feature_cols = [\n",
    "    \"Temperatur\",\n",
    "    \"KielerWoche\",\n",
    "    \"school_holiday\",\n",
    "    \"public_holiday\",\n",
    "    \"Month\",\n",
    "    \"sin_season\",\n",
    "    \"cos_season\",\n",
    "    \"is_weekend\",\n",
    "    \"lag_1\",\n",
    "    \"lag_2\",\n",
    "    \"lag_7\",\n",
    "    \"lag_14\",\n",
    "    \"roll7_mean\",\n",
    "    \"roll7_std\",\n",
    "    \"roll14_mean\",\n",
    "    \"roll14_std\",\n",
    "    \"roll30_mean\",\n",
    "    \"roll30_std\",\n",
    "] + weekday_cols + na_flag_cols\n",
    "\n",
    "print(\"NA-flag features:\", len(na_flag_cols))\n",
    "print(\"Example NA-flag cols:\", na_flag_cols[:5])\n",
    "\n",
    "\n",
    "target_col = \"umsatz\"\n",
    "\n",
    "# Export feature dataset (train only)\n",
    "features_dataset = train_fe[feature_cols + [target_col]].copy()\n",
    "\n",
    "features_dataset.to_csv(\n",
    "    \"nn_feature_dataset_train.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Saved: nn_feature_dataset_train.csv\")\n",
    "print(\"Number of features:\", len(feature_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4515606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim: int) -> tf.keras.Model:\n",
    "    model = Sequential([\n",
    "        Dense(64, activation=\"relu\", input_shape=(input_dim,)),\n",
    "        Dropout(0.1),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"mse\"\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e511272d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Warengruppe 1\n",
      "==============================\n",
      "Rows: train=1462, val=357, test=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.670 | MSE: 520.81 | MAE: 17.27 | MAPE: 15.66%\n",
      "NN R² (val):   0.555 | MSE: 799.08 | MAE: 21.25 | MAPE: 17.95%\n",
      "\n",
      "==============================\n",
      " Warengruppe 2\n",
      "==============================\n",
      "Rows: train=1462, val=357, test=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.882 | MSE: 2356.92 | MAE: 32.52 | MAPE: 7.95%\n",
      "NN R² (val):   0.891 | MSE: 1757.93 | MAE: 32.41 | MAPE: 9.32%\n",
      "\n",
      "==============================\n",
      " Warengruppe 3\n",
      "==============================\n",
      "Rows: train=1462, val=357, test=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.871 | MSE: 732.77 | MAE: 18.88 | MAPE: 12.79%\n",
      "NN R² (val):   0.869 | MSE: 749.80 | MAE: 20.37 | MAPE: 14.19%\n",
      "\n",
      "==============================\n",
      " Warengruppe 4\n",
      "==============================\n",
      "Rows: train=1409, val=357, test=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.597 | MSE: 557.89 | MAE: 16.67 | MAPE: 19.94%\n",
      "NN R² (val):   0.107 | MSE: 624.88 | MAE: 19.03 | MAPE: 24.36%\n",
      "\n",
      "==============================\n",
      " Warengruppe 5\n",
      "==============================\n",
      "Rows: train=1462, val=357, test=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.350 | MSE: 6709.13 | MAE: 36.56 | MAPE: 12.52%\n",
      "NN R² (val):   0.204 | MSE: 6178.53 | MAE: 42.77 | MAPE: 16.02%\n",
      "\n",
      "==============================\n",
      " Warengruppe 6\n",
      "==============================\n",
      "Rows: train=218, val=55, test=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN R² (train): 0.547 | MSE: 468.52 | MAE: 16.34 | MAPE: 28.81%\n",
      "NN R² (val):   0.540 | MSE: 448.11 | MAE: 16.69 | MAPE: 41.25%\n",
      "\n",
      "==============================\n",
      " Combined (weighted) metrics \n",
      "==============================\n",
      "Weighted R² (train): 0.670\n",
      "Weighted R² (val):   0.526\n",
      "Weighted MAPE (val): 17.11%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warengruppe</th>\n",
       "      <th>n_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "      <th>mse_train</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>mape_train</th>\n",
       "      <th>mse_val</th>\n",
       "      <th>mae_val</th>\n",
       "      <th>mape_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>357</td>\n",
       "      <td>0.669945</td>\n",
       "      <td>0.554714</td>\n",
       "      <td>520.813091</td>\n",
       "      <td>17.267093</td>\n",
       "      <td>15.659942</td>\n",
       "      <td>799.079266</td>\n",
       "      <td>21.252273</td>\n",
       "      <td>17.945842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>357</td>\n",
       "      <td>0.882130</td>\n",
       "      <td>0.890621</td>\n",
       "      <td>2356.919004</td>\n",
       "      <td>32.516132</td>\n",
       "      <td>7.953560</td>\n",
       "      <td>1757.925740</td>\n",
       "      <td>32.412289</td>\n",
       "      <td>9.318805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>357</td>\n",
       "      <td>0.871396</td>\n",
       "      <td>0.869389</td>\n",
       "      <td>732.774001</td>\n",
       "      <td>18.875385</td>\n",
       "      <td>12.791944</td>\n",
       "      <td>749.802650</td>\n",
       "      <td>20.374450</td>\n",
       "      <td>14.189145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>357</td>\n",
       "      <td>0.597066</td>\n",
       "      <td>0.107075</td>\n",
       "      <td>557.886194</td>\n",
       "      <td>16.672704</td>\n",
       "      <td>19.940724</td>\n",
       "      <td>624.875977</td>\n",
       "      <td>19.030242</td>\n",
       "      <td>24.363912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>357</td>\n",
       "      <td>0.350108</td>\n",
       "      <td>0.203997</td>\n",
       "      <td>6709.133938</td>\n",
       "      <td>36.559712</td>\n",
       "      <td>12.516593</td>\n",
       "      <td>6178.531279</td>\n",
       "      <td>42.771121</td>\n",
       "      <td>16.017694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>0.546743</td>\n",
       "      <td>0.540260</td>\n",
       "      <td>468.520971</td>\n",
       "      <td>16.343182</td>\n",
       "      <td>28.809968</td>\n",
       "      <td>448.110240</td>\n",
       "      <td>16.688609</td>\n",
       "      <td>41.254830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   warengruppe  n_val  r2_train    r2_val    mse_train  mae_train  mape_train  \\\n",
       "0            1    357  0.669945  0.554714   520.813091  17.267093   15.659942   \n",
       "1            2    357  0.882130  0.890621  2356.919004  32.516132    7.953560   \n",
       "2            3    357  0.871396  0.869389   732.774001  18.875385   12.791944   \n",
       "3            4    357  0.597066  0.107075   557.886194  16.672704   19.940724   \n",
       "4            5    357  0.350108  0.203997  6709.133938  36.559712   12.516593   \n",
       "5            6     55  0.546743  0.540260   468.520971  16.343182   28.809968   \n",
       "\n",
       "       mse_val    mae_val   mape_val  \n",
       "0   799.079266  21.252273  17.945842  \n",
       "1  1757.925740  32.412289   9.318805  \n",
       "2   749.802650  20.374450  14.189145  \n",
       "3   624.875977  19.030242  24.363912  \n",
       "4  6178.531279  42.771121  16.017694  \n",
       "5   448.110240  16.688609  41.254830  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: submission_neural_net.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>umsatz_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1808011</td>\n",
       "      <td>139.861282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1808012</td>\n",
       "      <td>625.553162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1808013</td>\n",
       "      <td>326.348114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1808014</td>\n",
       "      <td>82.955391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>1808015</td>\n",
       "      <td>284.468414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  umsatz_Prediction\n",
       "0     1808011         139.861282\n",
       "355   1808012         625.553162\n",
       "710   1808013         326.348114\n",
       "1065  1808014          82.955391\n",
       "1419  1808015         284.468414"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_groups = sorted(train_fe[\"warengruppe\"].dropna().unique())\n",
    "\n",
    "pred_list = []\n",
    "models_by_wg = {}\n",
    "results = []\n",
    "\n",
    "for wg in product_groups:\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\" Warengruppe {wg}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    train_wg = train_fe[train_fe[\"warengruppe\"] == wg].copy()\n",
    "    val_wg   = val_fe[val_fe[\"warengruppe\"] == wg].copy()\n",
    "    test_wg  = test_fe[test_fe[\"warengruppe\"] == wg].copy()\n",
    "\n",
    "    # Drop rows without target in train/val\n",
    "    train_wg = train_wg.dropna(subset=[target_col])\n",
    "    val_wg   = val_wg.dropna(subset=[target_col])\n",
    "\n",
    "    # Drop rows with missing FEATURES in train/val only\n",
    "    #train_wg = train_wg.dropna(subset=feature_cols)\n",
    "    #val_wg   = val_wg.dropna(subset=feature_cols)\n",
    "\n",
    "    # DO NOT drop test rows\n",
    "    print(f\"Rows: train={len(train_wg)}, val={len(val_wg)}, test={len(test_wg)}\")\n",
    "\n",
    "    if len(train_wg) < 50 or len(val_wg) < 20:\n",
    "        print(\"⚠️ Too few rows for stable NN training → skipping this WG.\")\n",
    "        continue\n",
    "\n",
    "    if len(test_wg) == 0:\n",
    "        print(\"⚠️ No test rows for this WG → skipping prediction.\")\n",
    "        continue\n",
    "\n",
    "    # ✅ Build X/y AFTER filtering\n",
    "    X_train = train_wg[feature_cols].to_numpy()\n",
    "    y_train = train_wg[target_col].to_numpy()\n",
    "\n",
    "    X_val   = val_wg[feature_cols].to_numpy()\n",
    "    y_val   = val_wg[target_col].to_numpy()\n",
    "\n",
    "    X_test  = test_wg[feature_cols].to_numpy()\n",
    "\n",
    "    # ✅ Impute\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_val   = imputer.transform(X_val)\n",
    "    X_test  = imputer.transform(X_test)\n",
    "\n",
    "    # ✅ Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val   = scaler.transform(X_val)\n",
    "    X_test  = scaler.transform(X_test)\n",
    "\n",
    "    # Train\n",
    "    model = build_model(input_dim=X_train.shape[1])\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        callbacks=[es],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    y_train_pred = model.predict(X_train, verbose=0).ravel()\n",
    "    y_val_pred   = model.predict(X_val, verbose=0).ravel()\n",
    "\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_val   = r2_score(y_val, y_val_pred)\n",
    "\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "    mape_train = mape(y_train, y_train_pred)\n",
    "\n",
    "    mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "    mae_val = mean_absolute_error(y_val, y_val_pred)\n",
    "    mape_val = mape(y_val, y_val_pred)\n",
    "\n",
    "    print(\n",
    "        f\"NN R² (train): {r2_train:.3f} | MSE: {mse_train:.2f} | MAE: {mae_train:.2f} | MAPE: {mape_train:.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"NN R² (val):   {r2_val:.3f} | MSE: {mse_val:.2f} | MAE: {mae_val:.2f} | MAPE: {mape_val:.2f}%\"\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"warengruppe\": wg,\n",
    "        \"n_val\": len(val_wg),\n",
    "        \"r2_train\": r2_train,\n",
    "        \"r2_val\": r2_val,\n",
    "        \"mse_train\": mse_train,\n",
    "        \"mae_train\": mae_train,\n",
    "        \"mape_train\": mape_train,\n",
    "        \"mse_val\": mse_val,\n",
    "        \"mae_val\": mae_val,\n",
    "        \"mape_val\": mape_val\n",
    "    })\n",
    "\n",
    "    # Predict test\n",
    "    y_test_pred = model.predict(X_test, verbose=0).ravel()\n",
    "\n",
    "    pred_list.append(pd.DataFrame({\n",
    "        \"id\": test_wg[\"id\"].values,\n",
    "        \"umsatz_Prediction\": y_test_pred\n",
    "    }))\n",
    "\n",
    "    models_by_wg[wg] = (model, scaler, imputer)\n",
    "\n",
    "# ==============================\n",
    "# Combined (weighted) evaluation\n",
    "# ==============================\n",
    "results_df = pd.DataFrame(results).sort_values(\"warengruppe\")\n",
    "\n",
    "weighted_r2_train = (results_df[\"r2_train\"] * results_df[\"n_val\"]).sum() / results_df[\"n_val\"].sum()\n",
    "weighted_r2_val   = (results_df[\"r2_val\"]   * results_df[\"n_val\"]).sum() / results_df[\"n_val\"].sum()\n",
    "\n",
    "weighted_mape_val = (results_df[\"mape_val\"] * results_df[\"n_val\"]).sum() / results_df[\"n_val\"].sum()\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\" Combined (weighted) metrics \")\n",
    "print(\"==============================\")\n",
    "print(f\"Weighted R² (train): {weighted_r2_train:.3f}\")\n",
    "print(f\"Weighted R² (val):   {weighted_r2_val:.3f}\")\n",
    "print(f\"Weighted MAPE (val): {weighted_mape_val:.2f}%\")\n",
    "\n",
    "display(results_df)  # optional (notebook only)\n",
    "\n",
    "# Submission\n",
    "if len(pred_list) == 0:\n",
    "    raise ValueError(\"No predictions generated. Check test split and IDs.\")\n",
    "\n",
    "submission = pd.concat(pred_list, ignore_index=True)\n",
    "submission = submission.dropna(subset=[\"id\"]).copy()\n",
    "submission[\"id\"] = submission[\"id\"].astype(int)\n",
    "submission = submission.sort_values(\"id\")\n",
    "submission.to_csv(\"submission_neural_net.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved: submission_neural_net.csv\")\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
