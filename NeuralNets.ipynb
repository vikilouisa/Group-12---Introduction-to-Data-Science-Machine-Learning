{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0165e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b36db166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (7475, 11) Val: (1840, 11) Test: (1830, 11)\n",
      "Train dates: 2013-07-01 00:00:00 â†’ 2017-07-31 00:00:00\n",
      "Val dates: 2017-08-01 00:00:00 â†’ 2018-07-31 00:00:00\n",
      "Test dates: 2018-08-01 00:00:00 â†’ 2019-07-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_split_merged_expanded_data.csv\", parse_dates=[\"date\"])\n",
    "val   = pd.read_csv(\"val_split_merged_expanded_data.csv\", parse_dates=[\"date\"])\n",
    "test  = pd.read_csv(\"test_split_merged_expanded_data_filtered.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "print(\"Train:\", train.shape, \"Val:\", val.shape, \"Test:\", test.shape)\n",
    "print(\"Train dates:\", train[\"date\"].min(), \"â†’\", train[\"date\"].max())\n",
    "print(\"Val dates:\", val[\"date\"].min(), \"â†’\", val[\"date\"].max())\n",
    "print(\"Test dates:\", test[\"date\"].min(), \"â†’\", test[\"date\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cf06bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering done.\n"
     ]
    }
   ],
   "source": [
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    # -------------------------\n",
    "    # Calendar features\n",
    "    # -------------------------\n",
    "    df[\"Wochentag\"] = df[\"date\"].dt.day_name()\n",
    "    df[\"Month\"]     = df[\"date\"].dt.month\n",
    "    df[\"dayofyear\"] = df[\"date\"].dt.dayofyear\n",
    "\n",
    "    # Seasonality encoding (cyclical)\n",
    "    df[\"sin_season\"] = np.sin(2 * np.pi * df[\"dayofyear\"] / 365)\n",
    "    df[\"cos_season\"] = np.cos(2 * np.pi * df[\"dayofyear\"] / 365)\n",
    "\n",
    "    df[\"is_weekend\"] = df[\"Wochentag\"].isin([\"Saturday\", \"Sunday\"]).astype(int)\n",
    "\n",
    "    # Integer/calendar flags (force 0/1 and no NaNs)\n",
    "    for col in [\"KielerWoche\", \"school_holiday\", \"public_holiday\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "train_fe = add_features(train)\n",
    "val_fe   = add_features(val)\n",
    "test_fe  = add_features(test)\n",
    "\n",
    "print(\"Feature engineering done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e73ef423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lag + rolling + one-hot done.\n"
     ]
    }
   ],
   "source": [
    "train_fe[\"dataset\"] = \"train\"\n",
    "val_fe[\"dataset\"]   = \"val\"\n",
    "test_fe[\"dataset\"]  = \"test\"\n",
    "\n",
    "df_all = pd.concat([train_fe, val_fe, test_fe], ignore_index=True)\n",
    "df_all = df_all.sort_values([\"warengruppe\", \"date\"])\n",
    "\n",
    "# Lags of target (umsatz) capture short-term and weekly memory\n",
    "for lag in [1, 2, 7, 14]:\n",
    "    df_all[f\"lag_{lag}\"] = df_all.groupby(\"warengruppe\")[\"umsatz\"].shift(lag)\n",
    "\n",
    "# Rolling mean & std (shift(1) avoids leakage)\n",
    "for window in [7, 14, 30]:\n",
    "    df_all[f\"roll{window}_mean\"] = (\n",
    "        df_all.groupby(\"warengruppe\")[\"umsatz\"].shift(1).rolling(window).mean()\n",
    "    )\n",
    "    df_all[f\"roll{window}_std\"] = (\n",
    "        df_all.groupby(\"warengruppe\")[\"umsatz\"].shift(1).rolling(window).std()\n",
    "    )\n",
    "\n",
    "# One-hot weekday (done on ALL so columns match across splits)\n",
    "df_all = pd.get_dummies(df_all, columns=[\"Wochentag\"], drop_first=False)\n",
    "\n",
    "train_fe = df_all[df_all[\"dataset\"] == \"train\"].copy()\n",
    "val_fe   = df_all[df_all[\"dataset\"] == \"val\"].copy()\n",
    "test_fe  = df_all[df_all[\"dataset\"] == \"test\"].copy()\n",
    "\n",
    "print(\"Lag + rolling + one-hot done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5568012d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 25\n"
     ]
    }
   ],
   "source": [
    "weekday_cols = [c for c in train_fe.columns if c.startswith(\"Wochentag_\")]\n",
    "\n",
    "feature_cols = [\n",
    "    \"Temperatur\",\n",
    "    \"KielerWoche\",\n",
    "    \"school_holiday\",\n",
    "    \"public_holiday\",\n",
    "    \"Month\",\n",
    "    \"sin_season\",\n",
    "    \"cos_season\",\n",
    "    \"is_weekend\",\n",
    "    \"lag_1\",\n",
    "    \"lag_2\",\n",
    "    \"lag_7\",\n",
    "    \"lag_14\",\n",
    "    \"roll7_mean\",\n",
    "    \"roll7_std\",\n",
    "    \"roll14_mean\",\n",
    "    \"roll14_std\",\n",
    "    \"roll30_mean\",\n",
    "    \"roll30_std\",\n",
    "] + weekday_cols\n",
    "\n",
    "target_col = \"umsatz\"\n",
    "\n",
    "print(\"Number of features:\", len(feature_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4515606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim: int) -> tf.keras.Model:\n",
    "    model = Sequential([\n",
    "        Dense(64, activation=\"relu\", input_shape=(input_dim,)),\n",
    "        Dropout(0.1),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"mse\"\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e511272d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Warengruppe 1\n",
      "==============================\n",
      "Rows: train=1432, val=357, test=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN RÂ² (train): 0.632 | MSE: 585.30 | MAE: 18.03\n",
      "NN RÂ² (val):   0.535 | MSE: 835.21 | MAE: 21.75\n",
      "\n",
      "==============================\n",
      " Warengruppe 2\n",
      "==============================\n",
      "Rows: train=1432, val=357, test=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN RÂ² (train): 0.871 | MSE: 2443.76 | MAE: 33.37\n",
      "NN RÂ² (val):   0.881 | MSE: 1911.93 | MAE: 33.70\n",
      "\n",
      "==============================\n",
      " Warengruppe 3\n",
      "==============================\n",
      "Rows: train=1432, val=357, test=355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN RÂ² (train): 0.870 | MSE: 703.90 | MAE: 18.49\n",
      "NN RÂ² (val):   0.872 | MSE: 737.50 | MAE: 20.37\n",
      "\n",
      "==============================\n",
      " Warengruppe 4\n",
      "==============================\n",
      "Rows: train=1379, val=357, test=354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN RÂ² (train): 0.597 | MSE: 566.80 | MAE: 16.83\n",
      "NN RÂ² (val):   0.066 | MSE: 653.58 | MAE: 19.45\n",
      "\n",
      "==============================\n",
      " Warengruppe 5\n",
      "==============================\n",
      "Rows: train=1432, val=357, test=355\n",
      "ðŸ”§ WG5: using regularized model\n",
      "NN RÂ² (train): 0.214 | MSE: 8178.73 | MAE: 40.49\n",
      "NN RÂ² (val):   0.133 | MSE: 6727.99 | MAE: 44.00\n",
      "\n",
      "==============================\n",
      " Warengruppe 6\n",
      "==============================\n",
      "Rows: train=188, val=55, test=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN RÂ² (train): 0.483 | MSE: 564.18 | MAE: 18.26\n",
      "NN RÂ² (val):   0.456 | MSE: 530.68 | MAE: 17.72\n",
      "\n",
      "==============================\n",
      " Combined (weighted) metrics \n",
      "==============================\n",
      "Weighted RÂ² (train): 0.632\n",
      "Weighted RÂ² (val):   0.496\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warengruppe</th>\n",
       "      <th>n_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "      <th>mse_train</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>mse_val</th>\n",
       "      <th>mae_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>357</td>\n",
       "      <td>0.631806</td>\n",
       "      <td>0.534583</td>\n",
       "      <td>585.296438</td>\n",
       "      <td>18.029734</td>\n",
       "      <td>835.205199</td>\n",
       "      <td>21.752499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>357</td>\n",
       "      <td>0.871034</td>\n",
       "      <td>0.881039</td>\n",
       "      <td>2443.759822</td>\n",
       "      <td>33.370163</td>\n",
       "      <td>1911.927371</td>\n",
       "      <td>33.698620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>357</td>\n",
       "      <td>0.870009</td>\n",
       "      <td>0.871531</td>\n",
       "      <td>703.897830</td>\n",
       "      <td>18.488386</td>\n",
       "      <td>737.501985</td>\n",
       "      <td>20.374660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>357</td>\n",
       "      <td>0.596873</td>\n",
       "      <td>0.066061</td>\n",
       "      <td>566.800017</td>\n",
       "      <td>16.828520</td>\n",
       "      <td>653.577895</td>\n",
       "      <td>19.448306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>357</td>\n",
       "      <td>0.213629</td>\n",
       "      <td>0.133209</td>\n",
       "      <td>8178.731876</td>\n",
       "      <td>40.488934</td>\n",
       "      <td>6727.985506</td>\n",
       "      <td>44.000670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>0.483359</td>\n",
       "      <td>0.455548</td>\n",
       "      <td>564.184173</td>\n",
       "      <td>18.257873</td>\n",
       "      <td>530.679312</td>\n",
       "      <td>17.717754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   warengruppe  n_val  r2_train    r2_val    mse_train  mae_train  \\\n",
       "0            1    357  0.631806  0.534583   585.296438  18.029734   \n",
       "1            2    357  0.871034  0.881039  2443.759822  33.370163   \n",
       "2            3    357  0.870009  0.871531   703.897830  18.488386   \n",
       "3            4    357  0.596873  0.066061   566.800017  16.828520   \n",
       "4            5    357  0.213629  0.133209  8178.731876  40.488934   \n",
       "5            6     55  0.483359  0.455548   564.184173  18.257873   \n",
       "\n",
       "       mse_val    mae_val  \n",
       "0   835.205199  21.752499  \n",
       "1  1911.927371  33.698620  \n",
       "2   737.501985  20.374660  \n",
       "3   653.577895  19.448306  \n",
       "4  6727.985506  44.000670  \n",
       "5   530.679312  17.717754  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: submission_neural_net.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>umsatz_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1808011</td>\n",
       "      <td>144.256165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1808012</td>\n",
       "      <td>635.488464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1808013</td>\n",
       "      <td>313.684540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1808014</td>\n",
       "      <td>82.766510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>1808015</td>\n",
       "      <td>294.597229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  umsatz_Prediction\n",
       "0     1808011         144.256165\n",
       "355   1808012         635.488464\n",
       "710   1808013         313.684540\n",
       "1065  1808014          82.766510\n",
       "1419  1808015         294.597229"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_groups = sorted(train_fe[\"warengruppe\"].dropna().unique())\n",
    "\n",
    "pred_list = []\n",
    "models_by_wg = {}\n",
    "results = []\n",
    "\n",
    "for wg in product_groups:\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\" Warengruppe {wg}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    train_wg = train_fe[train_fe[\"warengruppe\"] == wg].copy()\n",
    "    val_wg   = val_fe[val_fe[\"warengruppe\"] == wg].copy()\n",
    "    test_wg  = test_fe[test_fe[\"warengruppe\"] == wg].copy()\n",
    "\n",
    "    # Drop rows without target in train/val\n",
    "    train_wg = train_wg.dropna(subset=[target_col])\n",
    "    val_wg   = val_wg.dropna(subset=[target_col])\n",
    "\n",
    "    # Drop rows with missing FEATURES in train/val only\n",
    "    train_wg = train_wg.dropna(subset=feature_cols)\n",
    "    val_wg   = val_wg.dropna(subset=feature_cols)\n",
    "\n",
    "    # DO NOT drop test rows\n",
    "\n",
    "    print(f\"Rows: train={len(train_wg)}, val={len(val_wg)}, test={len(test_wg)}\")\n",
    "\n",
    "    if len(train_wg) < 50 or len(val_wg) < 20:\n",
    "        print(\"âš ï¸ Too few rows for stable NN training â†’ skipping this WG.\")\n",
    "        continue\n",
    "\n",
    "    if len(test_wg) == 0:\n",
    "        print(\"âš ï¸ No test rows for this WG â†’ skipping prediction.\")\n",
    "        continue\n",
    "\n",
    "    # âœ… Build X/y AFTER filtering\n",
    "    X_train = train_wg[feature_cols].to_numpy()\n",
    "    y_train = train_wg[target_col].to_numpy()\n",
    "\n",
    "    X_val   = val_wg[feature_cols].to_numpy()\n",
    "    y_val   = val_wg[target_col].to_numpy()\n",
    "\n",
    "    X_test  = test_wg[feature_cols].to_numpy()\n",
    "\n",
    "    # âœ… Impute\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_val   = imputer.transform(X_val)\n",
    "    X_test  = imputer.transform(X_test)\n",
    "\n",
    "    # âœ… Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val   = scaler.transform(X_val)\n",
    "    X_test  = scaler.transform(X_test)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Train (regularize only WG5)\n",
    "    # ------------------------------\n",
    "    if wg == 5:\n",
    "        print(\"ðŸ”§ WG5: using regularized model\")\n",
    "\n",
    "        reg = tf.keras.regularizers.l2(1e-3)\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "            tf.keras.layers.Dense(32, activation=\"relu\", kernel_regularizer=reg),\n",
    "            tf.keras.layers.Dropout(0.30),\n",
    "            tf.keras.layers.Dense(16, activation=\"relu\", kernel_regularizer=reg),\n",
    "            tf.keras.layers.Dropout(0.30),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=opt, loss=\"mse\")\n",
    "\n",
    "        es = EarlyStopping(monitor=\"val_loss\", patience=15, restore_best_weights=True)\n",
    "\n",
    "    else:\n",
    "        model = build_model(input_dim=X_train.shape[1])\n",
    "        es = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        callbacks=[es],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    y_train_pred = model.predict(X_train, verbose=0).ravel()\n",
    "    y_val_pred   = model.predict(X_val, verbose=0).ravel()\n",
    "\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_val   = r2_score(y_val, y_val_pred)\n",
    "\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "    mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "    mae_val = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "    print(f\"NN RÂ² (train): {r2_train:.3f} | MSE: {mse_train:.2f} | MAE: {mae_train:.2f}\")\n",
    "    print(f\"NN RÂ² (val):   {r2_val:.3f} | MSE: {mse_val:.2f} | MAE: {mae_val:.2f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"warengruppe\": wg,\n",
    "        \"n_val\": len(val_wg),\n",
    "        \"r2_train\": r2_train,\n",
    "        \"r2_val\": r2_val,\n",
    "        \"mse_train\": mse_train,\n",
    "        \"mae_train\": mae_train,\n",
    "        \"mse_val\": mse_val,\n",
    "        \"mae_val\": mae_val\n",
    "    })\n",
    "\n",
    "    # Predict test\n",
    "    y_test_pred = model.predict(X_test, verbose=0).ravel()\n",
    "\n",
    "    pred_list.append(pd.DataFrame({\n",
    "        \"id\": test_wg[\"id\"].values,\n",
    "        \"umsatz_Prediction\": y_test_pred\n",
    "    }))\n",
    "\n",
    "    models_by_wg[wg] = (model, scaler, imputer)\n",
    "\n",
    "# ==============================\n",
    "# Combined (weighted) evaluation\n",
    "# ==============================\n",
    "results_df = pd.DataFrame(results).sort_values(\"warengruppe\")\n",
    "\n",
    "weighted_r2_train = (\n",
    "    (results_df[\"r2_train\"] * results_df[\"n_val\"]).sum()\n",
    "    / results_df[\"n_val\"].sum()\n",
    ")\n",
    "\n",
    "weighted_r2_val = (\n",
    "    (results_df[\"r2_val\"] * results_df[\"n_val\"]).sum()\n",
    "    / results_df[\"n_val\"].sum()\n",
    ")\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\" Combined (weighted) metrics \")\n",
    "print(\"==============================\")\n",
    "print(f\"Weighted RÂ² (train): {weighted_r2_train:.3f}\")\n",
    "print(f\"Weighted RÂ² (val):   {weighted_r2_val:.3f}\")\n",
    "\n",
    "display(results_df)  # optional (notebook only)\n",
    "\n",
    "# Submission\n",
    "if len(pred_list) == 0:\n",
    "    raise ValueError(\"No predictions generated. Check test split and IDs.\")\n",
    "\n",
    "submission = pd.concat(pred_list, ignore_index=True)\n",
    "submission = submission.dropna(subset=[\"id\"]).copy()\n",
    "submission[\"id\"] = submission[\"id\"].astype(int)\n",
    "submission = submission.sort_values(\"id\")\n",
    "submission.to_csv(\"submission_neural_net.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved: submission_neural_net.csv\")\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
