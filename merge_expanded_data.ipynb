{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1f93ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading base files...\n",
      "Appending continuation file: /workspaces/Group-12---Introduction-to-Data-Science-Machine-Learning/analysis/test.csv\n",
      "Combined sales rows: 11164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_125932/3124034061.py:143: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_sales = pd.concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dates with missing sales (unique):\n",
      "            date  public_holiday  school_holiday\n",
      "2854  2013-07-12               0               1\n",
      "2879  2013-07-17               0               1\n",
      "2929  2013-07-27               0               1\n",
      "2934  2013-07-28               0               1\n",
      "2939  2013-07-29               0               1\n",
      "...          ...             ...             ...\n",
      "9439  2016-12-31               0               1\n",
      "9440  2017-01-01               1               0\n",
      "9955  2017-04-14               1               1\n",
      "10040 2017-05-01               1               0\n",
      "10360 2017-07-04               0               0\n",
      "\n",
      "[95 rows x 3 columns]\n",
      "\n",
      "Missing sales summary:\n",
      "Total dates: 95\n",
      "Public holiday counts:\n",
      "public_holiday\n",
      "0    76\n",
      "1    19\n",
      "Name: count, dtype: Int64\n",
      "School holiday counts:\n",
      "school_holiday\n",
      "0    48\n",
      "1    47\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Saved: missing_sales_dates.csv\n",
      "\n",
      "Wrote merged CSV to: /workspaces/Group-12---Introduction-to-Data-Science-Machine-Learning/merged_expanded_data_fullcalendar.csv\n",
      "Merged date range: 2012-01-01 00:00:00 → 2019-12-31 00:00:00\n",
      "Last non-empty umsatz date: 2018-07-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Notebook / root execution\n",
    "ROOT = Path.cwd()\n",
    "\n",
    "\n",
    "def find_date_column(df):\n",
    "    candidates = ['date', 'datum', 'Datum', 'DATUM']\n",
    "    for c in df.columns:\n",
    "        if c.lower() in [x.lower() for x in candidates]:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def read_and_normalize(path: Path):\n",
    "    df = pd.read_csv(path)\n",
    "    date_col = find_date_column(df)\n",
    "    if date_col is None:\n",
    "        raise ValueError(f\"No date column found in {path}\")\n",
    "    df[date_col] = pd.to_datetime(df[date_col], dayfirst=False, errors='coerce')\n",
    "    df = df.rename(columns={date_col: 'date'})\n",
    "    df = df.rename(columns={c: c.strip() for c in df.columns})\n",
    "    return df\n",
    "\n",
    "\n",
    "def find_column(df, keywords):\n",
    "    kws = [k.lower() for k in keywords]\n",
    "    for c in df.columns:\n",
    "        lc = c.lower()\n",
    "        for k in kws:\n",
    "            if k in lc:\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def standardize_sales_df(df):\n",
    "    # id\n",
    "    id_col = find_column(df, ['id'])\n",
    "    if id_col and id_col != 'id':\n",
    "        df = df.rename(columns={id_col: 'id'})\n",
    "\n",
    "    # warengruppe\n",
    "    war_col = find_column(df, ['wareng', 'warengruppe'])\n",
    "    if war_col and war_col != 'warengruppe':\n",
    "        df = df.rename(columns={war_col: 'warengruppe'})\n",
    "\n",
    "    # umsatz\n",
    "    u_col = find_column(df, ['umsatz'])\n",
    "    if u_col:\n",
    "        if u_col != 'umsatz':\n",
    "            df = df.rename(columns={u_col: 'umsatz'})\n",
    "        df['umsatz'] = pd.to_numeric(\n",
    "            df['umsatz'].astype(str).str.replace(',', '.'),\n",
    "            errors='coerce'\n",
    "        )\n",
    "    else:\n",
    "        df['umsatz'] = pd.NA\n",
    "\n",
    "    # ensure id exists\n",
    "    if 'id' not in df.columns:\n",
    "        df['id'] = pd.NA\n",
    "\n",
    "    df = df.rename(columns={c: c.strip() for c in df.columns})\n",
    "    return df\n",
    "\n",
    "\n",
    "def pick_existing(*paths: Path) -> Path:\n",
    "    for p in paths:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\n",
    "        \"None of these files exist:\\n\" + \"\\n\".join(str(p) for p in paths)\n",
    "    )\n",
    "\n",
    "\n",
    "def wg6_is_available(d: pd.Timestamp) -> bool:\n",
    "    # WG6 only exists in November and December\n",
    "    if pd.isna(d):\n",
    "        return False\n",
    "    return d.month in [11, 12]\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # --- base inputs ---\n",
    "    umsatz_path = ROOT / 'umsatzdaten_gekuerzt.csv'\n",
    "\n",
    "    wetter_path = pick_existing(\n",
    "        ROOT / 'wetter_imputed.csv',\n",
    "        ROOT / 'wetter_expanded.csv',\n",
    "        ROOT / 'wetter.csv',\n",
    "    )\n",
    "\n",
    "    kiwo_path = pick_existing(\n",
    "        ROOT / 'kiwo_expanded.csv',\n",
    "        ROOT / 'kiwo_clean_full_range.csv',\n",
    "        ROOT / 'kiwo.csv',\n",
    "    )\n",
    "\n",
    "    school_path = pick_existing(\n",
    "        ROOT / 'ferien_expanded.csv',\n",
    "        ROOT / 'ferien_clean_full_range.csv',\n",
    "        ROOT / 'Ferien_SH.csv',\n",
    "    )\n",
    "\n",
    "    public_path = pick_existing(\n",
    "        ROOT / 'feiertage_expanded.csv',\n",
    "        ROOT / 'feiertage_clean_full_range.csv',\n",
    "        ROOT / 'Feiertage_holidays_sh_2013_2019.csv',\n",
    "    )\n",
    "\n",
    "    # test.csv sometimes in ROOT, sometimes in ROOT/analysis\n",
    "    test_path = pick_existing(\n",
    "        ROOT / 'test.csv',\n",
    "        ROOT / 'analysis' / 'test.csv',\n",
    "    ) if ((ROOT / 'test.csv').exists() or (ROOT / 'analysis' / 'test.csv').exists()) else None\n",
    "\n",
    "    print('Reading base files...')\n",
    "    umsatz = read_and_normalize(umsatz_path)\n",
    "    wetter = read_and_normalize(wetter_path)\n",
    "    kiwo = read_and_normalize(kiwo_path)\n",
    "    school = read_and_normalize(school_path)\n",
    "    public = read_and_normalize(public_path)\n",
    "\n",
    "    # --- Standardize sales (+ optional continuation) ---\n",
    "    umsatz = standardize_sales_df(umsatz)\n",
    "\n",
    "    if test_path is not None and test_path.exists():\n",
    "        print(f'Appending continuation file: {test_path}')\n",
    "        test_df = read_and_normalize(test_path)\n",
    "        test_df = standardize_sales_df(test_df)\n",
    "\n",
    "        desired_cols = ['date', 'id', 'warengruppe', 'umsatz']\n",
    "        for c in desired_cols:\n",
    "            if c not in umsatz.columns:\n",
    "                umsatz[c] = pd.NA\n",
    "            if c not in test_df.columns:\n",
    "                test_df[c] = pd.NA\n",
    "\n",
    "        combined_sales = pd.concat(\n",
    "            [umsatz[desired_cols], test_df[desired_cols]],\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "        combined_sales['date'] = pd.to_datetime(combined_sales['date'], errors='coerce')\n",
    "        combined_sales['_id_sort'] = combined_sales['id'].astype(str).fillna('')\n",
    "        combined_sales = (\n",
    "            combined_sales\n",
    "            .sort_values(by=['date', '_id_sort'], na_position='last')\n",
    "            .drop(columns=['_id_sort'])\n",
    "        )\n",
    "\n",
    "        umsatz = combined_sales\n",
    "        print(f'Combined sales rows: {len(umsatz)}')\n",
    "\n",
    "    # Clean types for sales keys\n",
    "    umsatz['date'] = pd.to_datetime(umsatz['date'], errors='coerce')\n",
    "    umsatz['warengruppe'] = pd.to_numeric(umsatz['warengruppe'], errors='coerce')\n",
    "    umsatz['id'] = pd.to_numeric(umsatz['id'], errors='coerce')\n",
    "\n",
    "    # --- Normalize indicators ---\n",
    "    school_ind = find_column(school, ['school_holiday', 'ferien', 'schulferien'])\n",
    "    if school_ind is None or school_ind == 'date':\n",
    "        school['school_holiday'] = 1\n",
    "        school_ind = 'school_holiday'\n",
    "    school = school[['date', school_ind]].rename(columns={school_ind: 'school_holiday'})\n",
    "\n",
    "    public_ind = find_column(public, ['public_holiday', 'is_holiday', 'feiertag', 'holiday'])\n",
    "    if public_ind is None or public_ind == 'date':\n",
    "        public['public_holiday'] = 1\n",
    "        public_ind = 'public_holiday'\n",
    "    public = public[['date', public_ind]].rename(columns={public_ind: 'public_holiday'})\n",
    "\n",
    "    kiwo_ind = find_column(kiwo, ['kielerwoche', 'kiwo'])\n",
    "    if kiwo_ind and kiwo_ind not in ['KielerWoche', 'date']:\n",
    "        kiwo = kiwo.rename(columns={kiwo_ind: 'KielerWoche'})\n",
    "\n",
    "    # --- Build full date calendar for exogenous features ---\n",
    "    start_date = min(\n",
    "        wetter['date'].min(),\n",
    "        kiwo['date'].min(),\n",
    "        school['date'].min(),\n",
    "        public['date'].min(),\n",
    "        umsatz['date'].min(),\n",
    "    )\n",
    "    end_date = max(\n",
    "        wetter['date'].max(),\n",
    "        kiwo['date'].max(),\n",
    "        school['date'].max(),\n",
    "        public['date'].max(),\n",
    "    )\n",
    "\n",
    "    calendar = pd.DataFrame({'date': pd.date_range(start=start_date, end=end_date, freq='D')})\n",
    "\n",
    "    base = (\n",
    "        calendar\n",
    "        .merge(wetter, on='date', how='left')\n",
    "        .merge(kiwo, on='date', how='left')\n",
    "        .merge(school, on='date', how='left')\n",
    "        .merge(public, on='date', how='left')\n",
    "    )\n",
    "\n",
    "    # Force calendar flags to 0/1 Int64\n",
    "    for c in ['KielerWoche', 'school_holiday', 'public_holiday']:\n",
    "        if c in base.columns:\n",
    "            base[c] = pd.to_numeric(base[c], errors='coerce').fillna(0).astype('Int64')\n",
    "            base[c] = (base[c] > 0).astype('Int64')\n",
    "\n",
    "    # Weather ints\n",
    "    for c in ['Bewoelkung', 'Windgeschwindigkeit']:\n",
    "        if c in base.columns:\n",
    "            base[c] = pd.to_numeric(base[c], errors='coerce').round(0).astype('Int64')\n",
    "\n",
    "    # --- Build FULL (date × warengruppe) grid, with wg6 seasonal ---\n",
    "    warengruppen_all = [1, 2, 3, 4, 5]  # always\n",
    "    # build per-date grid\n",
    "    rows = []\n",
    "    for d in base['date']:\n",
    "        # always include 1..5\n",
    "        for wg in warengruppen_all:\n",
    "            rows.append((d, wg))\n",
    "        # include wg6 only in season\n",
    "        if wg6_is_available(d):\n",
    "            rows.append((d, 6))\n",
    "\n",
    "    grid = pd.DataFrame(rows, columns=['date', 'warengruppe'])\n",
    "\n",
    "    # Generate Kaggle-style id: yymmdd + warengruppe (as last digit)\n",
    "    grid['id'] = grid['date'].dt.strftime('%y%m%d').astype(int) * 10 + grid['warengruppe'].astype(int)\n",
    "\n",
    "    # --- Merge sales onto grid ---\n",
    "    sales_keys = umsatz[['date', 'warengruppe', 'id', 'umsatz']].copy()\n",
    "    # Keep only valid key rows\n",
    "    sales_keys = sales_keys.dropna(subset=['date', 'warengruppe', 'id'])\n",
    "\n",
    "    merged = grid.merge(sales_keys, on=['date', 'warengruppe', 'id'], how='left')\n",
    "\n",
    "    # --- Merge exogenous features onto every row ---\n",
    "    merged = merged.merge(base, on='date', how='left')\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # DIAGNOSTIC: list dates with missing sales in TRAIN RANGE\n",
    "    # (now correctly defined as: umsatz missing even though the row exists)\n",
    "    # ---------------------------------------------------------\n",
    "    start_diag = pd.to_datetime(\"2013-07-01\")\n",
    "    end_diag   = pd.to_datetime(\"2017-07-31\")\n",
    "\n",
    "    missing_sales_dates = (\n",
    "        merged[\n",
    "            (merged[\"date\"] >= start_diag) &\n",
    "            (merged[\"date\"] <= end_diag) &\n",
    "            (merged[\"umsatz\"].isna())\n",
    "        ][[\"date\", \"public_holiday\", \"school_holiday\"]]\n",
    "        .drop_duplicates()\n",
    "        .sort_values(\"date\")\n",
    "    )\n",
    "\n",
    "    print(\"\\nDates with missing sales (unique):\")\n",
    "    print(missing_sales_dates)\n",
    "\n",
    "    print(\"\\nMissing sales summary:\")\n",
    "    print(\"Total dates:\", len(missing_sales_dates))\n",
    "    print(\"Public holiday counts:\")\n",
    "    print(missing_sales_dates[\"public_holiday\"].value_counts(dropna=False))\n",
    "    print(\"School holiday counts:\")\n",
    "    print(missing_sales_dates[\"school_holiday\"].value_counts(dropna=False))\n",
    "\n",
    "    missing_sales_dates.to_csv(\"missing_sales_dates.csv\", index=False)\n",
    "    print(\"\\nSaved: missing_sales_dates.csv\")\n",
    "\n",
    "    # --- Final sorting/column order ---\n",
    "    merged = merged.sort_values(by=['date', 'warengruppe', 'id'], na_position='last')\n",
    "\n",
    "    preferred = [\n",
    "        'date', 'warengruppe', 'id', 'umsatz',\n",
    "        'Bewoelkung', 'Temperatur', 'Windgeschwindigkeit', 'Wettercode',\n",
    "        'KielerWoche', 'school_holiday', 'public_holiday'\n",
    "    ]\n",
    "    merged = merged[[c for c in preferred if c in merged.columns] +\n",
    "                    [c for c in merged.columns if c not in preferred]]\n",
    "\n",
    "    # --- Make umsatz blank (empty cell) instead of NaN in CSV ---\n",
    "    # (only affects output formatting; reading back will interpret blanks as NaN unless you set keep_default_na=False)\n",
    "    merged['umsatz'] = merged['umsatz'].apply(lambda x: '' if pd.isna(x) else x)\n",
    "\n",
    "    out_path = ROOT / 'merged_expanded_data_fullcalendar.csv'\n",
    "    merged.to_csv(out_path, index=False, na_rep='NaN')\n",
    "\n",
    "    print(f'\\nWrote merged CSV to: {out_path}')\n",
    "    print(\"Merged date range:\", merged['date'].min(), \"→\", merged['date'].max())\n",
    "    # last date with observed sales (not blank)\n",
    "    last_sales = merged.loc[merged['umsatz'].astype(str).str.len() > 0, 'date'].max()\n",
    "    print(\"Last non-empty umsatz date:\", last_sales)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print('Error during merge:', e, file=sys.stderr)\n",
    "        raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
