{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbd6b62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Warengruppe 1\n",
      "==============================\n",
      "Rows: train=1462, val=357, test=355\n",
      "Using 22 features for wg 1\n",
      "Full model R² (train): 0.514\n",
      "Full model R² (val):   0.476\n",
      "\n",
      "ANOVA-like variance partitioning:\n",
      " Feature Group      ΔR²  Reduced Model R²\n",
      "       Weekday 0.188475          0.325088\n",
      "Public Holiday 0.034388          0.479174\n",
      "School Holiday 0.017325          0.496237\n",
      "   Seasonality 0.012323          0.501239\n",
      "         Month 0.004358          0.509205\n",
      "\n",
      "==============================\n",
      " Warengruppe 2\n",
      "==============================\n",
      "Rows: train=1462, val=357, test=355\n",
      "Using 24 features for wg 2\n",
      "Full model R² (train): 0.854\n",
      "Full model R² (val):   0.862\n",
      "\n",
      "ANOVA-like variance partitioning:\n",
      " Feature Group      ΔR²  Reduced Model R²\n",
      "Public Holiday 0.020560          0.833907\n",
      "       Weekday 0.017006          0.837460\n",
      "School Holiday 0.004173          0.850294\n",
      "   KielerWoche 0.003262          0.851204\n",
      "         Month 0.003241          0.851225\n",
      "   Seasonality 0.002723          0.851743\n",
      "   Temperature 0.000166          0.854300\n",
      "\n",
      "==============================\n",
      " Warengruppe 3\n",
      "==============================\n",
      "Rows: train=1462, val=357, test=355\n",
      "Using 24 features for wg 3\n",
      "Full model R² (train): 0.845\n",
      "Full model R² (val):   0.848\n",
      "\n",
      "ANOVA-like variance partitioning:\n",
      " Feature Group      ΔR²  Reduced Model R²\n",
      "Public Holiday 0.012546          0.832381\n",
      "       Weekday 0.005014          0.839913\n",
      "School Holiday 0.004698          0.840229\n",
      "   KielerWoche 0.002062          0.842864\n",
      "   Seasonality 0.001611          0.843316\n",
      "         Month 0.000345          0.844582\n",
      "   Temperature 0.000337          0.844590\n",
      "\n",
      "==============================\n",
      " Warengruppe 4\n",
      "==============================\n",
      "Rows: train=1409, val=357, test=354\n",
      "Using 22 features for wg 4\n",
      "Full model R² (train): 0.523\n",
      "Full model R² (val):   0.182\n",
      "\n",
      "ANOVA-like variance partitioning:\n",
      " Feature Group      ΔR²  Reduced Model R²\n",
      "       Weekday 0.088439          0.434062\n",
      "Public Holiday 0.028921          0.493579\n",
      "   Seasonality 0.006303          0.516197\n",
      "         Month 0.003080          0.519420\n",
      "School Holiday 0.000686          0.521814\n",
      "\n",
      "==============================\n",
      " Warengruppe 5\n",
      "==============================\n",
      "Rows: train=1462, val=357, test=355\n",
      "Using 24 features for wg 5\n",
      "Full model R² (train): 0.248\n",
      "Full model R² (val):   0.248\n",
      "\n",
      "ANOVA-like variance partitioning:\n",
      " Feature Group      ΔR²  Reduced Model R²\n",
      "School Holiday 0.014537          0.233424\n",
      "         Month 0.014335          0.233626\n",
      "   Seasonality 0.012210          0.235751\n",
      "       Weekday 0.008345          0.239616\n",
      "Public Holiday 0.003952          0.244009\n",
      "   Temperature 0.002851          0.245110\n",
      "   KielerWoche 0.000759          0.247202\n",
      "\n",
      "==============================\n",
      " Warengruppe 6\n",
      "==============================\n",
      "Rows: train=218, val=55, test=56\n",
      "Using 24 features for wg 6\n",
      "Full model R² (train): 0.358\n",
      "Full model R² (val):   0.552\n",
      "\n",
      "ANOVA-like variance partitioning:\n",
      " Feature Group           ΔR²  Reduced Model R²\n",
      "   Seasonality  6.627801e-02          0.291437\n",
      "       Weekday  3.176178e-02          0.325953\n",
      "School Holiday  5.067503e-03          0.352647\n",
      "   Temperature  1.367719e-03          0.356347\n",
      "         Month  2.157849e-04          0.357499\n",
      "   KielerWoche  2.220446e-16          0.357715\n",
      "Public Holiday -1.110223e-16          0.357715\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>umsatz_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1808011</td>\n",
       "      <td>143.314043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1808012</td>\n",
       "      <td>584.764245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1808013</td>\n",
       "      <td>293.314359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1808014</td>\n",
       "      <td>64.127047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>1808015</td>\n",
       "      <td>283.177036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  umsatz_Prediction\n",
       "0     1808011         143.314043\n",
       "355   1808012         584.764245\n",
       "710   1808013         293.314359\n",
       "1065  1808014          64.127047\n",
       "1419  1808015         283.177036"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# =====================================================\n",
    "# 1. Load train / val + Kaggle test.csv (inside analysis/)\n",
    "# =====================================================\n",
    "\n",
    "train = pd.read_csv(\"train_split_merged_expanded_data.csv\")\n",
    "val   = pd.read_csv(\"val_split_merged_expanded_data.csv\")\n",
    "\n",
    "# Kaggle test template (has id/date/warengruppe; no umsatz)\n",
    "test  = pd.read_csv(\"analysis/test_split_merged_data_updated.csv\")\n",
    "\n",
    "# Keep ids for submission\n",
    "test_ids = test[\"id\"].copy()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Add exogenous features to Kaggle test.csv\n",
    "# We'll take them from merged_expanded_data_fullcalendar.csv\n",
    "# (1 row per date for weather + calendar flags)\n",
    "# -----------------------------------------------------\n",
    "\n",
    "features_src = pd.read_csv(\n",
    "    \"merged_expanded_data_fullcalendar.csv\",\n",
    "    parse_dates=[\"date\"]\n",
    ")\n",
    "\n",
    "# keep only one row per date (features are date-level)\n",
    "feat_cols = [\n",
    "    \"date\",\n",
    "    \"Temperatur\",\n",
    "    \"KielerWoche\",\n",
    "    \"school_holiday\",\n",
    "    \"public_holiday\",\n",
    "]\n",
    "feat_cols = [c for c in feat_cols if c in features_src.columns]\n",
    "\n",
    "features_daily = (\n",
    "    features_src[feat_cols]\n",
    "    .drop_duplicates(subset=[\"date\"])\n",
    "    .sort_values(\"date\")\n",
    ")\n",
    "\n",
    "# make sure test has date as datetime\n",
    "test[\"date\"] = pd.to_datetime(test[\"date\"])\n",
    "\n",
    "# merge features onto Kaggle test\n",
    "test = test.merge(features_daily, on=\"date\", how=\"left\")\n",
    "\n",
    "# Kaggle test has no target -> create it as NaN so concat works\n",
    "test[\"umsatz\"] = np.nan\n",
    "\n",
    "# Mark dataset type and concatenate so that lags/rolling\n",
    "# are computed consistently over time per warengruppe.\n",
    "train[\"dataset\"] = \"train\"\n",
    "val[\"dataset\"]   = \"val\"\n",
    "test[\"dataset\"]  = \"test\"\n",
    "df_all = pd.concat([train, val, test], ignore_index=True)\n",
    "\n",
    "# =====================================================\n",
    "# 2. Basic date & calendar features\n",
    "# =====================================================\n",
    "\n",
    "df_all[\"date\"] = pd.to_datetime(df_all[\"date\"])\n",
    "\n",
    "df_all[\"Wochentag\"] = df_all[\"date\"].dt.day_name()\n",
    "df_all[\"Month\"]     = df_all[\"date\"].dt.month\n",
    "df_all[\"dayofyear\"] = df_all[\"date\"].dt.dayofyear  # goes from 1 to 365 then jumps back to 1,\n",
    "# Additionally a linear model can’t naturally understand that Dec 31 and Jan 1 are “close”. Numerically they look far apart (365 vs 1)\n",
    "# That's why we use sine and cosine transformations to encode seasonality in a way that reflects the cyclical nature of the data.\n",
    "# The linear regression can now learn smooth yearly patterns like: high sales in summer, low sales in winter, spikes around certain times of year, etc.\n",
    "\n",
    "df_all[\"sin_season\"] = np.sin(2 * np.pi * df_all[\"dayofyear\"] / 365)\n",
    "df_all[\"cos_season\"] = np.cos(2 * np.pi * df_all[\"dayofyear\"] / 365)\n",
    "\n",
    "df_all[\"is_weekend\"] = df_all[\"Wochentag\"].isin([\"Saturday\", \"Sunday\"]).astype(int)\n",
    "\n",
    "# Integer/calendar flags\n",
    "for col in [\"KielerWoche\", \"school_holiday\", \"public_holiday\"]:\n",
    "    if col in df_all.columns:\n",
    "        df_all[col] = pd.to_numeric(df_all[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "    else:\n",
    "        df_all[col] = 0\n",
    "\n",
    "# =====================================================\n",
    "# 3. Lag features & rolling statistics per warengruppe\n",
    "# =====================================================\n",
    "\n",
    "# Sort so that groupby().shift() and rolling are correct in time\n",
    "df_all = df_all.sort_values([\"warengruppe\", \"date\"])\n",
    "\n",
    "# Lags (memory of the past) of target (umsatz): daily and weekly patterns\n",
    "# Lags are used because bakery demand is often autocorrelated; past sales influence future sales.\n",
    "# e.g. if croissant sales were high yesterday, they are likely to be high today too.\n",
    "# So with lags , the model also sees \"recent demand level\"\n",
    "for lag in [1, 2, 7, 14]:\n",
    "    df_all[f\"lag_{lag}\"] = (\n",
    "        df_all\n",
    "        .groupby(\"warengruppe\")[\"umsatz\"]\n",
    "        .shift(lag)\n",
    "    )\n",
    "\n",
    "# Rolling mean & std of past sales; smoothes the demand and cature \"recent level\" and \"volatility\"\n",
    "# \"shift(1)\" to avoid using current day's value in rolling stats, which would be cheating and avoids data leakage.\n",
    "# Rolling mean says \"on average, hoe much has this product group sold recently?\": smoothes out day-to-day noise.\n",
    "# Rolling std says \"how much does sales vary recently?\" or \"How stable is demand recently?\": captures volatility/ how noisy the data is.\n",
    "for window in [7, 14, 30]:\n",
    "    df_all[f\"roll{window}_mean\"] = (\n",
    "        df_all\n",
    "        .groupby(\"warengruppe\")[\"umsatz\"]\n",
    "        .shift(1)\n",
    "        .rolling(window)\n",
    "        .mean()\n",
    "    )\n",
    "    df_all[f\"roll{window}_std\"] = (\n",
    "        df_all\n",
    "        .groupby(\"warengruppe\")[\"umsatz\"]\n",
    "        .shift(1)\n",
    "        .rolling(window)\n",
    "        .std()\n",
    "    )\n",
    "\n",
    "# =====================================================\n",
    "# 4. One-hot encode weekday (on full df), then split back\n",
    "# =====================================================\n",
    "\n",
    "df_all = pd.get_dummies(df_all, columns=[\"Wochentag\"], drop_first=True)\n",
    "\n",
    "train_fe = df_all[df_all[\"dataset\"] == \"train\"].copy()\n",
    "val_fe   = df_all[df_all[\"dataset\"] == \"val\"].copy()\n",
    "test_fe  = df_all[df_all[\"dataset\"] == \"test\"].copy()\n",
    "\n",
    "# =====================================================\n",
    "# 5. Define feature set\n",
    "# =====================================================\n",
    "\n",
    "weekday_cols = [c for c in train_fe.columns if c.startswith(\"Wochentag_\")]\n",
    "\n",
    "feature_cols = [\n",
    "    \"Temperatur\",\n",
    "    \"KielerWoche\",\n",
    "    \"school_holiday\",\n",
    "    \"public_holiday\",\n",
    "    \"Month\",\n",
    "    \"sin_season\",\n",
    "    \"cos_season\",\n",
    "    \"is_weekend\",\n",
    "    \"lag_1\",\n",
    "    \"lag_2\",\n",
    "    \"lag_7\",\n",
    "    \"lag_14\",\n",
    "    \"roll7_mean\",\n",
    "    \"roll7_std\",\n",
    "    \"roll14_mean\",\n",
    "    \"roll14_std\",\n",
    "    \"roll30_mean\",\n",
    "    \"roll30_std\",\n",
    "] + weekday_cols\n",
    "\n",
    "target_col = \"umsatz\"\n",
    "\n",
    "# =====================================================\n",
    "# 5b. NEW: Per-warengruppe feature pruning\n",
    "# =====================================================\n",
    "\n",
    "FEATURES_BY_WG = {\n",
    "    1.0: [c for c in feature_cols if c not in [\"Temperatur\", \"KielerWoche\"]],\n",
    "    2.0: feature_cols,\n",
    "    3.0: feature_cols,\n",
    "    4.0: [c for c in feature_cols if c not in [\"Temperatur\", \"KielerWoche\"]],\n",
    "    5.0: feature_cols,  \n",
    "    6.0: feature_cols, \n",
    "}\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# helper: build model pipeline for a given feature list\n",
    "# =====================================================\n",
    "\n",
    "def build_model(cols):\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "            ]), cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"reg\", LinearRegression())\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# =====================================================\n",
    "# 6. Train one LinearRegression model per product group\n",
    "#    + ANOVA-like variance partitioning\n",
    "# =====================================================\n",
    "\n",
    "product_groups = sorted(train_fe[\"warengruppe\"].dropna().unique())\n",
    "pred_list = []\n",
    "models_by_wg = {}\n",
    "\n",
    "# Feature groups for ANOVA-like partitioning (must exist in \"features\" to be removable)\n",
    "feature_groups = {\n",
    "    \"Weekday\": weekday_cols,\n",
    "    \"School Holiday\": [\"school_holiday\"],\n",
    "    \"Public Holiday\": [\"public_holiday\"],\n",
    "    \"Seasonality\": [\"sin_season\", \"cos_season\"],\n",
    "    \"Month\": [\"Month\"],\n",
    "    \"KielerWoche\": [\"KielerWoche\"],\n",
    "    \"Temperature\": [\"Temperatur\"],\n",
    "}\n",
    "\n",
    "for wg in product_groups:\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\" Warengruppe {wg}\")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    train_wg = train_fe[train_fe[\"warengruppe\"] == wg].copy()\n",
    "    val_wg   = val_fe[val_fe[\"warengruppe\"] == wg].copy()\n",
    "    test_wg  = test_fe[test_fe[\"warengruppe\"] == wg].copy()\n",
    "\n",
    "    features = FEATURES_BY_WG.get(float(wg), feature_cols)\n",
    "\n",
    "    print(f\"Rows: train={len(train_wg)}, val={len(val_wg)}, test={len(test_wg)}\")\n",
    "    print(f\"Using {len(features)} features for wg {wg}\")\n",
    "\n",
    "    X_train = train_wg[features]\n",
    "    y_train = train_wg[target_col]\n",
    "\n",
    "    X_val = val_wg[features]\n",
    "    y_val = val_wg[target_col]\n",
    "\n",
    "    X_test = test_wg[features]\n",
    "\n",
    "    # --- Full model ---\n",
    "    full_model = build_model(features)\n",
    "    full_model.fit(X_train, y_train)\n",
    "    models_by_wg[wg] = full_model\n",
    "\n",
    "    # R² on training data\n",
    "    y_train_pred = full_model.predict(X_train)\n",
    "    full_r2_train = r2_score(y_train, y_train_pred)\n",
    "    print(f\"Full model R² (train): {full_r2_train:.3f}\")\n",
    "\n",
    "    # R² on validation data\n",
    "    y_val_pred = full_model.predict(X_val)\n",
    "    full_r2_val = r2_score(y_val, y_val_pred)\n",
    "    print(f\"Full model R² (val):   {full_r2_val:.3f}\")\n",
    "\n",
    "    # --- ANOVA-like variance partitioning (TRAIN R²) ---\n",
    "    rows = []\n",
    "    for group_name, cols_in_group in feature_groups.items():\n",
    "        cols_in_group = [c for c in cols_in_group if c in features]\n",
    "        if len(cols_in_group) == 0:\n",
    "            continue\n",
    "\n",
    "        reduced_cols = [c for c in features if c not in cols_in_group]\n",
    "        if len(reduced_cols) == 0:\n",
    "            continue\n",
    "\n",
    "        reduced_model = build_model(reduced_cols)\n",
    "        reduced_model.fit(train_wg[reduced_cols], y_train)\n",
    "\n",
    "        y_reduced_pred = reduced_model.predict(train_wg[reduced_cols])\n",
    "        r2_reduced = r2_score(y_train, y_reduced_pred)\n",
    "\n",
    "        rows.append({\n",
    "            \"Feature Group\": group_name,\n",
    "            \"ΔR²\": full_r2_train - r2_reduced,\n",
    "            \"Reduced Model R²\": r2_reduced\n",
    "        })\n",
    "\n",
    "    if len(rows) > 0:\n",
    "        var_table = (\n",
    "            pd.DataFrame(rows)\n",
    "            .sort_values(\"ΔR²\", ascending=False)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        print(\"\\nANOVA-like variance partitioning:\")\n",
    "        print(var_table.to_string(index=False))\n",
    "\n",
    "    # --- Predict on TEST ---\n",
    "    y_test_pred = full_model.predict(X_test)\n",
    "\n",
    "    pred_list.append(\n",
    "        pd.DataFrame({\n",
    "            \"id\": test_wg[\"id\"].values,\n",
    "            \"umsatz_Prediction\": y_test_pred\n",
    "        })\n",
    "    )\n",
    "\n",
    "# =====================================================\n",
    "# 7. Build submission file\n",
    "# =====================================================\n",
    "\n",
    "submission = pd.concat(pred_list, ignore_index=True).sort_values(\"id\")\n",
    "submission.to_csv(\"submission_linear_regression_byGulfem_2.csv\", index=False)\n",
    "\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
